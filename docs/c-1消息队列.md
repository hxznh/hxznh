# 消息队列

## 什么是MQ

MQ(message queue)，从字面意思上看，本质是个队列， FIFO 先入先出，只不过队列中存放的内容是message 而已，还是一种跨进程的通信机制，用于上下游传递消息。在互联网架构中， MQ 是一种非常常见的上下游“逻辑解耦+物理解耦” 的消息通信服务。使用了 MQ 之后，消息发送上游只需要依赖 MQ，不用依赖其他服务  

## 为什么需要MQ

1. 流量削峰

   举个例子，如果订单系统最多能处理一万次订单，这个处理能力应付正常时段的下单时绰绰有余，正常时段我们下单一秒后就能返回结果。但是在高峰期，如果有两万次下单操作系统是处理不了的，只能限制订单超过一万后不允许用户下单。使用消息队列做缓冲，我们可以取消这个限制，把一秒内下的订单分散成一段时间来处理，这时有些用户可能在下单十几秒后才能收到下单成功的操作，但是比不能下单的体验要好。

2. 应用解耦
   以电商应用为例，应用中有订单系统、库存系统、物流系统、支付系统。用户创建订单后，如果耦合调用库存系统、物流系统、支付系统，任何一个子系统出了故障，都会造成下单操作异常。当转变成基于消息队列的方式后，系统间调用的问题会减少很多，比如物流系统因为发生故障，需要几分钟来修复。在这几分钟的时间里，物流系统要处理的内存被缓存在消息队列中，用户的下单操作可以正常完成。当物流系统恢复后，继续处理订单信息即可，中单用户感受不到物流系统的故障，提升系统的可用性。 

   开发过程中，利用消息队列，可以实现开发过程中的解耦，比如上下游服务之间的调用，就可以利用消息队列进行数据交互。如果不使用消息队列，则需要通过rpc进行远程调用，会使代码强耦合。 

<img src="https://cdn.jsdelivr.net/gh/hxznh/images@main/image-20220909180108530.png" alt="image-20220909180108530" style="zoom: 50%;" />

3. 异步处理
   有些服务间调用是异步的，例如 A 调用 B， B 需要花费很长时间执行，但是 A 需要知道 B 什么时候可以执行完，以前一般有两种方式， A 过一段时间去调用 B 的查询 api 查询。或者 A 提供一个 callback api，B 执行完之后调用 api 通知 A 服务。这两种方式都不是很优雅，使用消息总线，可以很方便解决这个问题，A 调用 B 服务后，只需要监听 B 处理完成的消息，当 B 处理完成后，会发送一条消息给 MQ， MQ 会将此消息转发给 A 服务。这样 A 服务既不用循环调用 B 的查询 api，也不用提供 callback api。同样B 服务也不用做这些操作。 A 服务还能及时的得到异步处理成功的消息。  

<img src="https://cdn.jsdelivr.net/gh/hxznh/images@main/image-20220909180331915.png" alt="image-20220909180331915" style="zoom: 50%;" />



## MQ 的分类

### ActiveMQ

> 优点

单机吞吐量万级，时效性 ms 级，可用性高，基于主从架构实现高可用性，消息可靠性较低的概率丢失数据

> 缺点

官方社区现在对 ActiveMQ 5.x 维护越来越少，高吞吐量场景较少使用。

### Kafka

以其**百万级 TPS** 的吞吐量名声大噪，迅速成为大数据领域的宠儿，在数据采集、传输、存储的过程中发挥着举足轻重的作用。目前已经被 LinkedIn， Uber, Twitter, Netflix 等大公司所采纳。

> 优点

- 性能卓越，单机写入 TPS 约在百万条/秒，最大的优点，就是吞吐量高。时效性 ms 级可用性非常高， kafka 是分布式的，一个数据多个副本，少数机器宕机，不会丢失数据，不会导致不可用,消费者采用 Pull 方式获取消息
- 消息有序, 通过控制能够保证所有消息被消费且仅被消费一次;
- 有优秀的第三方KafkaWeb 管理界面 Kafka-Manager；在日志领域比较成熟，被多家公司和多个开源项目使用；
- 功能支持：功能较为简单，主要支持简单的 MQ 功能，在大数据领域的实时计算以及日志采集被大规模使用

> 缺点

- Kafka 单机超过 64 个队列/分区， Load 会发生明显的飙高现象，队列越多， load 越高，发送消息响应时间变长，使用短轮询方式，实时性取决于轮询间隔时间，消费失败不支持重试；
- **支持消息顺序**，但是一台代理宕机后，就会产生消息乱序
- **社区更新较慢**；

### RocketMQ

RocketMQ 出自阿里巴巴的开源产品，用 Java 语言实现，在设计时参考了 Kafka，并做出了自己的一些改进。被阿里巴巴广泛应用在订单，交易，充值，流计算，消息推送，日志流式处理， binglog 分发等场景。

> 优点

- **单机吞吐量十万级**,可用性非常高，分布式架构,消息可以做到 0 丢失,MQ 功能较为完善，还是分布式的，扩展性好
- **支持 10 亿级别的消息堆积**，不会因为堆积导致性能下降
- 源码是 java 我们可以自己阅读源码，定制自己公司的 MQ

> 缺点

- **支持的客户端语言不多**，目前是 java 及 c++，其中 c++不成熟；
- 社区活跃度一般,没有在MQ核心中去实现 JMS 等接口,有些系统要迁移需要修改大量代码

### RabbitMQ

2007 年发布，是一个在AMQP(高级消息队列协议)基础上完成的，可复用的企业消息系统，是当前最主流的消息中间件之一。

> 优点

由于 erlang 语言的高并发特性，性能较好； 吞吐量到万级， MQ 功能比较完备,健壮、稳定、易用、跨平台、 支持多种语言 如： Python、 Ruby、 .NET、 Java、 JMS、 C、 PHP、 ActionScript、 XMPP、 STOMP等，支持 AJAX 文档齐全；开源提供的管理界面非常棒，用起来很好用,社区活跃度高；更新频率相当高
https://www.rabbitmq.com/news.html

> 缺点

商业版需要收费,学习成本较高  



## MQ的选择

1. Kafka
   Kafka 主要特点是基于Pull 的模式来处理消息消费，追求高吞吐量，一开始的目的就是用于日志收集和传输，适合产生大量数据的互联网服务的数据收集业务。 大型公司建议可以选用，如果有日志采集功能，肯定是首选 kafka 了。
2. RocketMQ
   天生为金融互联网领域而生，对于可靠性要求很高的场景，尤其是电商里面的订单扣款，以及业务削峰，在大量交易涌入时，后端可能无法及时处理的情况。 RoketMQ 在稳定性上可能更值得信赖，这些业务场景在阿里双 11 已经经历了多次考验，如果你的业务有上述并发场景，建议可以选择 RocketMQ。
3. RabbitMQ
   结合 erlang 语言本身的并发优势，性能好时效性微秒级， 社区活跃度也比较高，管理界面用起来十分方便，如果你的数据量没有那么大，中小型公司优先选择功能比较完备的 RabbitMQ。  







## RabbitMQ

官网：https://www.rabbitmq.com/

### 概念

RabbitMQ 是一个消息中间件：它接收，存储和转发消息数据。  

### 四大核心概念

- 生产者
  产生数据发送消息的程序是生产者
- 交换机
  交换机是 RabbitMQ 非常重要的一个部件，一方面它接收来自生产者的消息，另一方面它将消息推送到队列中。交换机必须确切知道如何处理它接收到的消息，是将这些消息推送到特定队列还是推送到多个队列，亦或者是把消息丢弃，这个得有交换机类型决定
- 队列<br>队列是 RabbitMQ 内部使用的一种数据结构，尽管消息流经 RabbitMQ 和应用程序，但它们只能存储在队列中。队列仅受主机的内存和磁盘限制的约束，本质上是一个大的消息缓冲区。许多生产者可以将消息发送到一个队列，许多消费者可以尝试从一个队列接收数据。这就是我们使用队列的方式
- 消费者
  消费与接收具有相似的含义。消费者大多时候是一个等待接收消息的程序。请注意,生产者，消费者和消息中间件很多时候并不在同一机器上。同一个应用程序既可以是生产者又是可以是消费者  

### RabbitMQ 核心部分  

<img src="https://cdn.jsdelivr.net/gh/hxznh/images@main/image-20220909183918219.png" alt="image-20220909183918219" style="zoom:67%;" />

<img src="https://cdn.jsdelivr.net/gh/hxznh/images@main/image-20220909183928960.png" alt="image-20220909183928960" style="zoom:67%;" />

### 名词介绍

<img src="https://cdn.jsdelivr.net/gh/hxznh/images@main/image-20230817152557314.png" alt="image-20230817152557314" style="zoom:67%;" />

- **Broker**：接收和分发消息的应用， RabbitMQ Server 就是 Message Broker
- **Virtual host**：出于多租户和安全因素设计的，把 AMQP 的基本组件划分到一个虚拟的分组中，类似于网络中的 namespace 概念。当多个不同的用户使用同一个 RabbitMQ server 提供的服务时，可以划分出多个 vhost，每个用户在自己的 vhost 创建 exchange／ queue 等
- **Connection**： publisher／ consumer 和 broker 之间的 TCP 连接
- **Channel**：如果每一次访问 RabbitMQ 都建立一个 Connection，在消息量大的时候建立 TCP Connection 的开销将是巨大的，效率也较低。 Channel 是在 connection 内部建立的逻辑连接，如果应用程序支持多线程，通常每个 thread 创建单独的 channel 进行通讯， AMQP method 包含了 channel id 帮助客户端和 message broker 识别 channel，所以 channel 之间是完全隔离的。 Channel 作为轻量级的 Connection 极大减少了操作系统建立 TCP connection 的开销
- **Exchange**： message 到达 broker 的第一站，根据分发规则，匹配查询表中的 routing key，分发消息到 queue 中去。常用的类型有： direct (point-to-point), topic (publish-subscribe) and fanout (multicast)
- **Queue**： 消息最终被送到这里等待 consumer 取走
- **Binding**： exchange 和 queue 之间的虚拟连接， binding 中可以包含 routing key， Binding 信息被保存到 **exchange** 中的查询表中，用于 message 的分发依据

### 消息应答

#### 概念

消费者完成一个任务可能需要一段时间，如果其中一个消费者处理一个长的任务并仅只完成了部分突然它挂掉了，会发生什么情况。 RabbitMQ 一旦向消费者传递了一条消息，便立即将该消息标记为删除。在这种情况下，突然有个消费者挂掉了，我们将丢失正在处理的消息。以及后续发送给该消费这的消息，因为它无法接收到。

为了保证消息在发送过程中不丢失， rabbitmq 引入消息应答机制，消息应答就是:**消费者在接收到消息并且处理该消息之后，告诉 rabbitmq 它已经处理了， rabbitmq 可以把该消息删除了**  

#### 自动应答

消息发送后立即被认为已经传送成功，这种模式需要在高吞吐量和数据传输安全性方面做权衡,因为这种模式如果消息在接收到之前，消费者那边出现连接或者 channel 关闭，那么消息就丢失了,当然另一方面这种模式消费者那边可以传递过载的消息， 没有对传递的消息数量进行限制， 当然这样有可能使得消费者这边由于接收太多还来不及处理的消息，导致这些消息的积压，最终使得内存耗尽，最终这些消费者线程被操作系统杀死， 所以这种模式仅适用在消费者可以高效并以某种速率能够处理这些消息的情况下使用。  

#### 消息应答的方法

A.Channel.basicAck(用于肯定确认)  RabbitMQ 已知道该消息并且成功的处理消息，可以将其丢弃了
B.Channel.basicNack(用于否定确认)
C.Channel.basicReject(用于否定确认)  与 Channel.basicNack 相比少一个参数，不处理该消息了直接拒绝，可以将其丢弃了  

#### Multiple 的解释

手动应答的好处是可以批量应答并且减少网络拥堵

```java
channel.basicAck(develeryTag, true);
```

multiple 的 true 和 false 代表不同意思

- true 代表批量应答 channel 上未应答的消息
  - 比如说 channel 上有传送 tag 的消息 5,6,7,8 当前 tag 是8 那么此时 5-8 的这些还未应答的消息都会被确认收到消息应答
- false 同上面相比只会应答 tag=8 的消息 5,6,7 这三个消息依然不会被确认收到消息应答

<img src="https://cdn.jsdelivr.net/gh/hxznh/images@main/image-20220910162257492.png" alt="image-20220910162257492" style="zoom:67%;" />



如果消费者由于某些原因失去连接(其通道已关闭，连接已关闭或 TCP 连接丢失)，导致消息未发送 ACK 确认， RabbitMQ 将了解到消息未完全处理，并将对其重新排队。如果此时其他消费者可以处理，它将很快将其重新分发给另一个消费者。这样，即使某个消费者偶尔死亡，也可以确保不会丢失任何消息。  

<img src="https://cdn.jsdelivr.net/gh/hxznh/images@main/image-20220910162440934.png" alt="image-20220910162440934" style="zoom: 67%;" />

#### 消息手动应答代码

默认消息采用的是自动应答，所以我们要想实现消息消费过程中不丢失，需要把自动应答改为手动应答，消费者在上面代码的基础上增加下面画红色部分代码。  

待补



#### 手动应答效果演示

正常情况下消息发送方发送两个消息 C1 和 C2 分别接收到消息并进行处理

在发送者发送消息 dd， 发出消息之后的把 C2 消费者停掉，按理说该 C2 来处理该消息，但是由于它处理时间较长，在还未处理完，也就是说 C2 还没有执行 ack 代码的时候， C2 被停掉了，
此时会看到消息被 C1 接收到了，说明消息 dd 被重新入队，然后分配给能处理消息的 C1 处理了  

<img src="https://cdn.jsdelivr.net/gh/hxznh/images@main/image-20220910163648903.png" alt="image-20220910163648903" style="zoom: 50%;" />



### RabbitMQ 持久化

#### 概念

刚刚我们已经看到了如何处理任务不丢失的情况，但是如何保障当 RabbitMQ 服务停掉以后消息生产者发送过来的消息不丢失。默认情况下 RabbitMQ 退出或由于某种原因崩溃时，它忽视队列和消息，除非告知它不要这样做。确保消息不会丢失需要做两件事： 我们需要将队列和消息都标记为持久化。

#### 队列如何实现持久化

之前我们创建的队列都是非持久化的， rabbitmq 如果重启的话，该队列就会被删除掉，如果要队列实现持久化 需要在声明队列的时候把 durable 参数设置为持久化

但是需要注意的就是如果之前声明的队列不是持久化的，需要把原先队列先删除，或者重新创建一个持久化的队列，不然就会出现错误

以下为控制台中持久化与非持久化队列的 UI 显示区、  

<img src="https://cdn.jsdelivr.net/gh/hxznh/images@main/image-20220910163735172.png" alt="image-20220910163735172" style="zoom:50%;" />

这个时候即使重启 rabbitmq 队列也依然存在  

#### 消息实现持久化

要想让消息实现持久化需要在消息生产者修改代码， `MessageProperties.PERSISTENT_TEXT_PLAIN` 添加这个属性。

```java
channel.basicPublish("", queueName, null, message.getBytes());
									↓
channel.basicPublish("", queueName, MessageProperties.PERSISTENT_TEXT_PLAIN, message.getBytes());
```

将消息标记为持久化并不能完全保证不会丢失消息。尽管它告诉 RabbitMQ 将消息保存到磁盘，但是这里依然存在当消息刚准备存储在磁盘的时候 但是还没有存储完，消息还在缓存的一个间隔点。此时并没有真正写入磁盘。持久性保证并不强，但是对于我们的简单任务队列而言，这已经绰绰有余了。如果需要更强有力的持久化策略，参考后边发布确认章节  

### 不公平分发

在最开始的时候我们学习到 RabbitMQ 分发消息采用的轮训分发，但是在某种场景下这种策略并不是很好，比方说有两个消费者在处理任务，其中有个消费者 1 处理任务的速度非常快，而另外一个消费者 2 处理速度却很慢，这个时候我们还是采用轮训分发的化就会到这处理速度快的这个消费者很大一部分时间处于空闲状态，而处理慢的那个消费者一直在干活，这种分配方式在这种情况下其实就不太好，但是RabbitMQ 并不知道这种情况它依然很公平的进行分发。

为了避免这种情况，我们可以设置参数 `channel.basicQos(1)`;  



![image-20220910172014634](https://cdn.jsdelivr.net/gh/hxznh/images@main/image-20220910172014634.png)

意思就是如果这个任务我还没有处理完或者我还没有应答你，你先别分配给我，我目前只能处理一个任务，然后 rabbitmq 就会把该任务分配给没有那么忙的那个空闲消费者，当然如果所有的消费者都没有完成手上任务，队列还在不停的添加新任务，队列有可能就会遇到队列被撑满的情况，这个时候就只能添加新的 worker 或者改变其他存储任务的策略。  

### 预取值

本身消息的发送就是异步发送的，所以在任何时候， channel 上肯定不止只有一个消息。另外，来自消费者的手动确认本质上也是异步的。因此这里就存在一个未确认的消息缓冲区，因此希望开发人员能限制此缓冲区的大小，以避免缓冲区里面无限制的未确认消息问题。这个时候就可以通过使用 basic.qos 方法设置“预取计数” 值来完成的。该值定义通道上允许的未确认消息的最大数量。一旦数量达到配置的数量，RabbitMQ 将停止在通道上传递更多消息，除非至少有一个未处理的消息被确认，例如，假设在通道上有未确认的消息 5、 6、 7， 8，并且通道的预取计数设置为 4，此时RabbitMQ 将不会在该通道上再传递任何消息，除非至少有一个未应答的消息被 ack。比方说 tag=6 这个消息刚刚被确认 ACK， RabbitMQ 将会感知这个情况到并再发送一条消息。消息应答和 QoS 预取值对用户吞吐量有重大影响。通常，增加预取将提高向消费者传递消息的速度。 **虽然自动应答传输消息速率是最佳的，但是，在这种情况下已传递但尚未处理的消息的数量也会增加，从而增加了消费者的 RAM 消耗**(随机存取存储器)应该小心使用具有无限预处理的自动确认模式或手动确认模式，消费者消费了大量的消息如果没有确认的话，会导致消费者连接节点的内存消耗变大，所以找到合适的预取值是一个反复试验的过程，不同的负载该值取值也不同 100 到 300 范围内的值通常可提供最佳的吞吐量，并且不会给消费者带来太大的风险。预取值为 1 是最保守的。当然这将使吞吐量变得很低，特别是消费者连接延迟很严重的情况下，特别是在消费者连接等待时间较长的环境中。对于大多数应用来说，稍微高一点的值将是最佳的。  

<img src="https://cdn.jsdelivr.net/gh/hxznh/images@main/image-20220910172238511.png" alt="image-20220910172238511" style="zoom:50%;" />

### 发布确认

#### 发布确认原理

生产者将信道设置成 confirm 模式，一旦信道进入 confirm 模式， 所有在该信道上面发布的消息都将会被指派一个唯一的 ID(从 1 开始)，一旦消息被投递到所有匹配的队列之后， broker 就会发送一个确认给生产者(包含消息的唯一 ID)，这就使得生产者知道消息已经正确到达目的队列了，如果消息和队列是可持久化的，那么确认消息会在将消息写入磁盘之后发出， broker 回传给生产者的确认消息中 delivery-tag 域包含了确认消息的序列号，此外 broker 也可以设置basic.ack 的 multiple 域，表示到这个序列号之前的所有消息都已经得到了处理。

confirm 模式最大的好处在于他是异步的，一旦发布一条消息，生产者应用程序就可以在等信道返回确认的同时继续发送下一条消息，当消息最终得到确认之后，生产者应用便可以通过回调方法来处理该确认消息，如果 RabbitMQ 因为自身内部错误导致消息丢失，就会发送一条 nack 消息，生产者应用程序同样可以在回调方法中处理该 nack 消息

#### 发布确认的策略

##### 开启发布确认的方法

发布确认默认是没有开启的，如果要开启需要调用方法 confirmSelect，每当你要想使用发布确认，都需要在 channel 上调用该方法  

`channel.confirmSelect()`

##### 单个确认发布

这是一种简单的确认方式，它是一种同步确认发布的方式，也就是发布一个消息之后只有它被确认发布，后续的消息才能继续发布,waitForConfirmsOrDie(long)这个方法只有在消息被确认的时候才返回，如果在指定时间范围内这个消息没有被确认那么它将抛出异常。

这种确认方式有一个最大的缺点就是:**发布速度特别的慢**， 因为如果没有确认发布的消息就会阻塞所有后续消息的发布，这种方式最多提供每秒不超过数百条发布消息的吞吐量。当然对于某些应用程序来说这可能已经足够了。  

```java
for (int i = 0; i < MESSAGE_COUNT; i++) {
    String message = i + "";
    channel.basicPublish("", queueName, null, message.getBytes());
    //服务端返回 false 或超时时间内未返回，生产者可以消息重发
    boolean flag = channel.waitForConfirms();
    if(flag) {
        System.out.println("消息发送成功");
    }
}
```



##### 批量确认发布

上面那种方式非常慢，与单个等待确认消息相比，先发布一批消息然后一起确认可以极大地提高吞吐量，当然这种方式的缺点就是:当发生故障导致发布出现问题时，不知道是哪个消息出现问题了，我们必须将整个批处理保存在内存中，以记录重要的信息而后重新发布消息。当然这种方案仍然是同步的，也一样阻塞消息的发布。  

```java
for (int i = 0; i < MESSAGE_COUNT; i++) {
    String message = i + "";
    channel.basicPublish("", queueName, null, message.getBytes());
    outstandingMessageCount++;
    if (outstandingMessageCount == batchSize) {
        channel.waitForConfirms();
        outstandingMessageCount = 0;
    }
}
```

##### 异步确认发布

异步确认虽然编程逻辑比上两个要复杂，但是性价比最高，无论是可靠性还是效率都没得说，他是利用回调函数来达到消息可靠性传递的，这个中间件也是通过函数回调来保证是否投递成功，下面就让我们来详细讲解异步确认是怎么实现的。  

![image-20220910184645750](https://cdn.jsdelivr.net/gh/hxznh/images@main/image-20220910184645750.png)



##### 如何处理异步未确认消息

最好的解决的解决方案就是把未确认的消息放到一个基于内存的能被发布线程访问的队列，
比如说用 ConcurrentLinkedQueue 这个队列在 confirm callbacks 与发布线程之间进行消息的传递。

##### 以上 3 种发布确认速度对比

- 单独发布消息
  同步等待确认，简单，但吞吐量非常有限。
- 批量发布消息
  批量同步等待确认，简单，合理的吞吐量，一旦出现问题但很难推断出是哪条消息出现了问题。
- 异步处理
  最佳性能和资源使用，在出现错误的情况下可以很好地控制，但是实现起来稍微难些  

### 交换机

在上一节中，我们创建了一个工作队列。我们假设的是工作队列背后，每个任务都恰好交付给一个消费者(工作进程)。在这一部分中，我们将做一些完全不同的事情-我们将消息传达给多个消费者。这种模式称为 ”发布/订阅”.

为了说明这种模式，我们将构建一个简单的日志系统。它将由两个程序组成:第一个程序将发出日志消息，第二个程序是消费者。其中我们会启动两个消费者，其中一个消费者接收到消息后把日志存储在磁盘, 另外一个消费者接收到消息后把消息打印在屏幕上，事实上第一个程序发出的日志消息将广播给所有消费者  

#### Exchanges 概念

RabbitMQ 消息传递模型的核心思想是: 生产者生产的消息从不会直接发送到队列。实际上，通常生产者甚至都不知道这些消息传递传递到了哪些队列中。

相反， 生产者只能将消息发送到交换机(exchange)，交换机工作的内容非常简单，一方面它接收来自生产者的消息，另一方面将它们推入队列。交换机必须确切知道如何处理收到的消息。是应该把这些消息放到特定队列还是说把他们到许多队列中还是说应该丢弃它们。这就的由交换机的类型来决定。  

<img src="https://cdn.jsdelivr.net/gh/hxznh/images@main/image-20220910194057334.png" alt="image-20220910194057334" style="zoom:67%;" />





#### Exchanges 的类型

总共有以下类型：
直接(direct), 主题(topic) ,标题(headers) , 扇出(fanout)

#### 默认exchange

在本教程的前面部分我们对 exchange 一无所知，但仍然能够将消息发送到队列。之前能实现的原因是因为我们使用的是默认交换，我们通过空字符串(“”)进行标识。  

第一个参数是交换机的名称。空字符串表示默认或无名称交换机：消息能路由发送到队列中其实是由 routingKey (bindingkey)绑定 key 指定的，如果它存在的话  

#### 临时队列

之前的章节我们使用的是具有特定名称的队列(还记得 hello 和 ack_queue 吗？ )。队列的名称我们来说至关重要-我们需要指定我们的消费者去消费哪个队列的消息。
每当我们连接到 Rabbit 时，我们都需要一个全新的空队列，为此我们可以创建一个具有随机名称的队列，或者能让服务器为我们选择一个随机队列名称那就更好了。其次一旦我们断开了消费者的连接，队列将被自动删除。
创建临时队列的方式如下:`String queueName = channel.queueDeclare().getQueue();`
创建出来之后长成这样:  

<img src="https://cdn.jsdelivr.net/gh/hxznh/images@main/image-20220910194931565.png" alt="image-20220910194931565" style="zoom:67%;" />

#### 绑定(bindings)

什么是 bingding 呢， binding 其实是 exchange 和 queue 之间的桥梁，它告诉我们 exchange 和那个队列进行了绑定关系。比如说下面这张图告诉我们的就是 X 与 Q1 和 Q2 进行了绑定  

<img src="https://cdn.jsdelivr.net/gh/hxznh/images@main/image-20220910194953668.png" alt="image-20220910194953668" style="zoom: 67%;" />

#### Fanout exchange

> Fanout 介绍

Fanout 这种类型非常简单。正如从名称中猜到的那样，它是将接收到的所有消息广播到它知道的所有队列中。系统中默认有些 exchange

<img src="https://cdn.jsdelivr.net/gh/hxznh/images@main/image-20220910195036180.png" alt="image-20220910195036180" style="zoom:67%;" />



#### Direct exchange

> Direct exchange 介绍

例如我们希望将日志消息写入磁盘的程序仅接收严重错误(errros)，而不存储哪些警告(warning)或信息(info)日志
消息避免浪费磁盘空间。 Fanout 这种交换类型并不能给我们带来很大的灵活性-它只能进行无意识的广播，在这里我们将使用 direct 这种类型来进行替换，这种类型的工作方式是，消息只去到它绑定的 routingKey 队列中去。  

<img src="https://cdn.jsdelivr.net/gh/hxznh/images@main/image-20220910195207973.png" alt="image-20220910195207973" style="zoom:67%;" />

在上面这张图中，我们可以看到 X 绑定了两个队列，绑定类型是 direct。队列Q1 绑定键为 orange，队列 Q2 绑定键有两个:一个绑定键为 black，另一个绑定键为 green.
在这种绑定情况下，生产者发布消息到 exchange 上，绑定键为 orange 的消息会被发布到队列Q1。绑定键为 blackgreen 和的消息会被发布到队列 Q2，其他消息类型的消息将被丢弃。  

#### 多重绑定

<img src="https://cdn.jsdelivr.net/gh/hxznh/images@main/image-20220910200705579.png" alt="image-20220910200705579" style="zoom: 67%;" />


当然如果 exchange 的绑定类型是direct， 但是它绑定的多个队列的 key 如果都相同，在这种情况下虽然绑定类型是 direct 但是它表现的就和 fanout 有点类似了，就跟广播差不多，如上图所示。  

#### Topics Exchange

> 之前类型的问题

在上一个小节中，我们改进了日志记录系统。我们没有使用只能进行随意广播的 fanout 交换机，而是使用了 direct 交换机，从而有能实现有选择性地接收日志。  

尽管使用direct 交换机改进了我们的系统，但是它仍然存在局限性-比方说我们想接收的日志类型有 info.base 和 info.advantage，某个队列只想 info.base 的消息，那这个时候direct 就办不到了。这个时候就只能使用a

> Topic 的要求

发送到类型是 topic 交换机的消息的 routing_key 不能随意写，必须满足一定的要求，它必须是一个单词列表，以点号分隔开。这些单词可以是任意单词，比如说： "stock.usd.nyse", "nyse.vmw","quick.orange.rabbit".这种类型的。当然这个单词列表最多不能超过 255 个字节。

在这个规则列表中，其中有两个替换符是大家需要注意的

- ~~*~~ (星号)可以代替一个单词
- ~~#~~(井号)可以替代零个或多个单词

> Topic 匹配案例

下图绑定关系如下

- Q1-->绑定的是
  中间带 orange 带 3 个单词的字符串(`*.orange.*`)
- Q2-->绑定的是
  最后一个单词是 rabbit 的 3 个单词(`*.*.rabbit`)
  第一个单词是 lazy 的多个单词(`lazy.#`)  

<img src="https://cdn.jsdelivr.net/gh/hxznh/images@main/image-20220910201421477.png" alt="image-20220910201421477" style="zoom:67%;" />

上图是一个队列绑定关系图，我们来看看他们之间数据接收情况是怎么样的
quick.orange.rabbit 被队列 Q1Q2 接收到
lazy.orange.elephant 被队列 Q1Q2 接收到
quick.orange.fox 被队列 Q1 接收到
lazy.brown.fox 被队列 Q2 接收到
lazy.pink.rabbit 虽然满足两个绑定但只被队列 Q2 接收一次
quick.brown.fox 不匹配任何绑定不会被任何队列接收到会被丢弃
quick.orange.male.rabbit 是四个单词不匹配任何绑定会被丢弃
lazy.orange.male.rabbit 是四个单词但匹配 Q2  

> 当队列绑定关系是下列这种情况时需要引起注意

当一个队列绑定键是#,那么这个队列将接收所有数据，就有点像 fanout 了

如果队列绑定键当中没有#和*出现，那么该队列绑定类型就是 direct 了  

### 死信队列

#### 死信的概念

先从概念解释上搞清楚这个定义，死信，顾名思义就是无法被消费的消息，字面意思可以这样理解，一般来说， producer 将消息投递到 broker 或者直接到queue 里了， consumer 从 queue 取出消息进行消费，但某些时候由于特定的原因导致 queue 中的某些消息无法被消费，这样的消息如果没有后续的处理，就变成了死信，有死信自然就有了死信队列。

应用场景:为了保证订单业务的消息数据不丢失，需要使用到 RabbitMQ 的死信队列机制，当消息消费发生异常时，将消息投入死信队列中.还有比如说: 用户在商城下单成功并点击去支付后在指定时间未支付时自动失效

> 死信的来源

- 消息 TTL 过期
- 队列达到最大长度(队列满了，无法再添加数据到 mq 中)
- 消息被拒绝(basic.reject 或 basic.nack)并且 requeue=false.  

> 架构

<img src="https://cdn.jsdelivr.net/gh/hxznh/images@main/image-20220910213657967.png" alt="image-20220910213657967" style="zoom:67%;" />



### 延迟队列

#### 延迟队列概念

延时队列,队列内部是有序的，最重要的特性就体现在它的延时属性上，延时队列中的元素是希望在指定时间到了以后或之前取出和处理，简单来说，延时队列就是用来存放需要在指定时间被处理的元素的队列。

> 使用场景

1. 订单在十分钟之内未支付则自动取消
2. 新创建的店铺，如果在十天内都没有上传过商品，则自动发送消息提醒。
3. 用户注册成功后，如果三天内没有登陆则进行短信提醒。
4. 用户发起退款，如果三天内没有得到处理则通知相关运营人员。、
5. 预定会议后，需要在预定的时间点前十分钟通知各个与会人员参加会议 

这些场景都有一个特点，需要在某个事件发生之后或者之前的指定时间点完成某一项任务，如：发生订单生成事件，在十分钟之后检查该订单支付状态，然后将未支付的订单进行关闭；看起来似乎使用定时任务，一直轮询数据，每秒查一次，取出需要被处理的数据，然后处理不就完事了吗？如果数据量比较少，确实可以这样做，比如：对于“如果账单一周内未支付则进行自动结算” 这样的需求，如果对于时间不是严格限制，而是宽松意义上的一周，那么每天晚上跑个定时任务检查一下所有未支付的账单，确实也是一个可行的方案。但对于数据量比较大，并且时效性较强的场景，如： “订单十分钟内未支付则关闭“，短期内未支付的订单数据可能会有很多，活动期间甚至会达到百万甚至千万级别，对这么庞大的数据量仍旧使用轮询的方式显然是不可取的，很可能在一秒内无法完成所有订单的检查，同时会给数据库带来很大压力，无法满足业务要求而且性能低下。  

#### RabbitMQ 中的 TTL

TTL 是什么呢？ TTL 是 RabbitMQ 中一个消息或者队列的属性，表明一条消息或者该队列中的所有消息的最大存活时间，  

单位是毫秒。换句话说，如果一条消息设置了 TTL 属性或者进入了设置TTL 属性的队列，那么这条消息如果在TTL 设置的时间内没有被消费，则会成为"死信"。如果同时配置了队列的TTL 和消息的TTL，那么较小的那个值将会被使用，有两种方式设置 TTL。  

- 消息设置TTL
  一种方式便是针对每条消息设置TTL  

  <img src="https://cdn.jsdelivr.net/gh/hxznh/images@main/image-20220910220916664.png" alt="image-20220910220916664" style="zoom: 50%;" />

- 队列设置TTL
  第一种是在创建队列的时候设置队列的“x-message-ttl” 属性  

  <img src="https://cdn.jsdelivr.net/gh/hxznh/images@main/image-20220910220930912.png" alt="image-20220910220930912" style="zoom:50%;" />

> 两者的区别

如果设置了队列的 TTL 属性，那么一旦消息过期，就会被队列丢弃(如果配置了死信队列被丢到死信队列中)，而第二种方式，消息即使过期，也不一定会被马上丢弃，因为**消息是否过期是在即将投递到消费者之前判定的，**如果当前队列有严重的消息积压情况，则已过期的消息也许还能存活较长时间；另外，还需要注意的一点是，如果不设置 TTL，表示消息永远不会过期，如果将 TTL 设置为 0，则表示除非此时可以直接投递该消息到消费者，否则该消息将会被丢弃。

至此利用 RabbitMQ 实现延时队列的两大要素已经集齐，想想看，延时队列，不就是想要消息延迟多久被处理吗， TTL 则刚好能让消息在延迟多久之后成为死信，另一方面，成为死信的消息都会被投递到死信队列里，这样只需要消费者一直消费死信队列里的消息就完事了，因为里面的消息都是希望被立即处理的消息。  

##### 队列 TTL  

> 代码架构图

创建两个队列 QA 和 QB，两者队列 TTL 分别设置为 10S 和 40S，然后在创建一个交换机 X 和死信交换机 Y，它们的类型都是direct，创建一个死信队列 QD，它们的绑定关系如下：  

<img src="https://cdn.jsdelivr.net/gh/hxznh/images@main/image-20220910221214592.png" alt="image-20220910221214592" style="zoom:50%;" />

不过，如果这样使用的话，**岂不是每增加一个新的时间需求，就要新增一个队列**，这里只有 10S 和 40S两个时间选项，如果需要一个小时后处理，那么就需要增加TTL 为一个小时的队列，如果是预定会议室然后提前通知这样的场景，岂不是要增加无数个队列才能满足需求？  

### 延时队列优化

> 代码架构图

在这里新增了一个队列 QC,绑定关系如下,该队列不设置TTL 时间  

<img src="https://cdn.jsdelivr.net/gh/hxznh/images@main/image-20220910221321936.png" alt="image-20220910221321936" style="zoom: 50%;" />

<img src="../../../面试/面经总结.assets/image-20220910221513375.png" alt="image-20220910221513375" style="zoom: 50%;" />

看起来似乎没什么问题，但是在最开始的时候，就介绍过如果使用在消息属性上设置 TTL 的方式，消息可能并不会按时“死亡“，因为 RabbitMQ **只会检查第一个消息是否过期，**如果过期则丢到死信队列**，如果第一个消息的延时时长很长，而第二个消息的延时时长很短，第二个消息并不会优先得到执行**  

#### Rabbitmq 插件实现延迟队列

上文中提到的问题，确实是一个问题，如果不能实现在消息粒度上的 TTL，并使其在设置的TTL 时间及时死亡，就无法设计成一个通用的延时队列。那如何解决呢，接下来我们就去解决该问题。  

在官网上下载 https://www.rabbitmq.com/community-plugins.html，下载
rabbitmq_delayed_message_exchange 插件，然后解压放置到 RabbitMQ 的插件目录。
进入 RabbitMQ 的安装目录下的 plgins 目录，执行下面命令让该插件生效，然后重启 RabbitMQ

/usr/lib/rabbitmq/lib/rabbitmq_server-3.8.8/plugins
rabbitmq-plugins enable rabbitmq_delayed_message_exchange  

<img src="https://cdn.jsdelivr.net/gh/hxznh/images@main/image-20220910221702656.png" alt="image-20220910221702656" style="zoom: 50%;" />

> 代码架构图

在这里新增了一个队列delayed.queue,一个自定义交换机 delayed.exchange，绑定关系如下:  

<img src="https://cdn.jsdelivr.net/gh/hxznh/images@main/image-20220910221743246.png" alt="image-20220910221743246" style="zoom:50%;" />

### 其他知识点

#### 幂等性

> 概念

用户对于同一操作发起的一次请求或者多次请求的结果是一致的，不会因为多次点击而产生了副作用。举个最简单的例子，那就是支付，用户购买商品后支付，支付扣款成功，但是返回结果的时候网络异常，此时钱已经扣了，用户再次点击按钮，此时会进行第二次扣款，返回结果成功，用户查询余额发现多扣钱了，流水记录也变成了两条。在以前的单应用系统中，我们只需要把数据操作放入事务中即可，发生错误立即回滚，但是再响应客户端的时候也有可能出现网络中断或者异常等等  

> 消息重复消费

消费者在消费 MQ 中的消息时， MQ 已把消息发送给消费者，消费者在给MQ 返回 ack 时网络中断，故 MQ 未收到确认信息，该条消息会重新发给其他的消费者，或者在网络重连后再次发送给该消费者，但实际上该消费者已成功消费了该条消息，造成消费者消费了重复的消息。

> 解决思路

MQ 消费者的幂等性的解决一般使用全局 ID 或者写个唯一标识比如时间戳 或者 UUID 或者订单消费者消费 MQ 中的消息也可利用 MQ 的该 id 来判断，或者可按自己的规则生成一个全局唯一 id，每次消费消息时用该 id 先判断该消息是否已消费过。

> 消费端的幂等性保障

在海量订单生成的业务高峰期，生产端有可能就会重复发生了消息，这时候消费端就要实现幂等性，这就意味着我们的消息永远不会被消费多次，即使我们收到了一样的消息。业界主流的幂等性有两种操作:a.唯一 ID+指纹码机制,利用数据库主键去重, b.利用 redis 的原子性去实现

> 唯一ID+指纹码机制

指纹码:我们的一些规则或者时间戳加别的服务给到的唯一信息码,它并不一定是我们系统生成的，基本都是由我们的业务规则拼接而来，但是一定要保证唯一性，然后就利用查询语句进行判断这个 id 是否存在数据库中,优势就是实现简单就一个拼接，然后查询判断是否重复；劣势就是在高并发时，如果是单个数据库就会有写入性能瓶颈当然也可以采用分库分表提升性能，但也不是我们最推荐的方式。

> Redis 原子性

利用 redis 执行 setnx 命令，天然具有幂等性。从而实现不重复消费  

#### 漏消费

丢数据一般有两种情况：一种是MQ把数据丢了，一种是消费时把数据丢了。
 **场景1**
 生产者将数据发送到RabbitMQ的时候，传输过程中因为**网络等问题将数据丢了**
 解决办法：
 ①**启用RaibbitMQ提供的事务功能**，生产者发送数据前开启事务，如果消息没有成功被RabbitMQ接收到，生产者会报错，这时候可以回滚事务，然后尝试重新发送。缺点就是RabbitMQ开启事务会变成同步阻塞操作，使用事务消息， 性能下降250倍， 所以引入消息确认机制
 ② **发送方确认机制**。 生产者配置开启发送方确认模式，并设置确认回调。 只要消息到达 Broker（消息代理）， 就会触发confirmCallback, 表示服务器成功收到消息。消息用数据库记录，定时检查重发没有成功的消息
 还得开启发送端消息抵达队列确认，并设置回调。如果消息成功抵达 broker， 不一定能成功投递到队列，如果交换机没能成功将消息投递到队列，就会触发 returnCallBack

**场景2**
 **RabbitMQ 断电重启**了，导致丢消息。
 针对这种情况，RabbitMQ有自己的持久化功能，可以把消息持久化到磁盘，RabbitMQ重启后自动读取之前存储的数据。
 而且持久化可以和发送方确认机制配合，消息持久化到磁盘后才会回复发送方ack，这样生产者收不到ack回调，也会重发消息。

**场景3**
 **消费者消费的时候挂了**。导致数据丢失

针对这种情况，使用RabbitMQ的 消费端确认机制。 首先关闭 RabbitMQ 的自动 ACK，每次确保处理完消息之后，再手动调用ack。这样服务器宕机或者bug导致没有正确ack， 消息会重新入队。



#### 优先级队列

> 使用场景

在我们系统中有一个订单催付的场景，我们的客户在天猫下的订单,淘宝会及时将订单推送给我们，如果在用户设定的时间内未付款那么就会给用户推送一条短信提醒，很简单的一个功能对吧，但是， tmall商家对我们来说，肯定是要分大客户和小客户的对吧，比如像苹果，小米这样大商家一年起码能给我们创造很大的利润，所以理应当然，他们的订单必须得到优先处理，而曾经我们的后端系统是使用 redis 来存放的定时轮询，大家都知道 redis 只能用 List 做一个简简单单的消息队列，并不能实现一个优先级的场景，所以订单量大了后采用 RabbitMQ 进行改造和优化,如果发现是大客户的订单给一个相对比较高的优先级，
否则就是默认优先级。  



> 优先级队列

```java
Map<String, Object> arguments = new HashMap<>();
arguments.put("x-max-priority", 10);    // 设置最大权重，官方允许 0-255之间
channel.queueDeclare(queueName, true, false, true, arguments);
// 消息内容
```

> 设置消息优先级

```java
AMQP.BasicProperties properties =
    new AMQP.BasicProperties().builder().priority(5).build();
channel.basicPublish("", queueName, properties, message.getBytes());
```

#### 惰性队列

> 使用场景

RabbitMQ 从 3.6.0 版本开始引入了惰性队列的概念。惰性队列会==尽可能==的将消息存入磁盘中，而在消费者消费到相应的消息时才会被加载到内存中，它的一个重要的设计目标是能够支持更长的队列，即支持更多的消息存储。当==消费者==由于各种各样的原因(比如==消费者下线、宕机亦或者是由于维护而关闭等==)而致使长时间内不能消费消息造成堆积时，惰性队列就很有必要了。

默认情况下，当生产者将消息发送到 RabbitMQ 的时候，队列中的消息会尽可能的存储在内存之中，这样可以更加快速的将消息发送给消费者。即使是持久化的消息，在被写入磁盘的同时也会在内存中驻留一份备份。当 RabbitMQ 需要释放内存的时候，会将内存中的消息换页至磁盘中，这个操作会耗费较长的时间，也会阻塞队列的操作，进而无法接收新的消息。虽然 RabbitMQ 的开发者们一直在升级相关的算法，但是效果始终不太理想，尤其是在消息量特别大的时候  

> 两种模式

队列具备两种模式： `default` 和 `lazy`。默认的为 `default` 模式，在3.6.0 之前的版本无需做任何变更。 lazy模式即为惰性队列的模式，可以通过调用 channel.queueDeclare 方法的时候在参数中设置，也可以通过Policy 的方式设置，如果一个队列同时使用这两种方式设置的话，那么 Policy 的方式具备更高的优先级。如果要通过声明的方式改变已有队列的模式的话，那么只能先删除队列，然后再重新声明一个新的。
在队列声明的时候可以通过“x-queue-mode”参数来设置队列的模式，取值为“default”和“lazy”。下面示例中演示了一个惰性队列的声明细节：

```java
Map<String, Object> args = new HashMap<String, Object>();
args.put("x-queue-mode", "lazy");
channel.queueDeclare("myqueue", false, false, false, args);  
```



#### 报错处理

```java
Caused by: com.rabbitmq.client.ShutdownSignalException: channel error; protocol method: #method<channel.close>(reply-code=406, reply-text=PRECONDITION_FAILED - inequivalent arg 'x-max-length' for queue 'ttl.direct.queue' in vhost '/': received the value '500' of type 'signedint' but current is none, class-id=50, method-id=10)

// ttl.direct.queue 已存在，且配置了新的参数，不接收。需要删除已存在的队列，重新启动
```



### 面试题

#### 请你说下RabbitMq的优缺点

> 优点

	1. 解耦 

   	2. 异步：减少请求的等待
   	3. 削峰限流：将所有的请求都写道消息队列中，按服务器能处理的请求消费	

> 缺点

   	1. 系统的可用性降低：系统引用的外部依赖越多，越可能出问题，可能会造成雪崩
   	2. 系统的复杂度提高：加入消息对列后需要保证消息没有重复消费，以及如何处理消息丢失的问题
   	3. 数据一致性的问题：若BCD三个系统，BD系统写入成功，C系统写库失败，导致数据不一致性

#### RabbitMq的组成部分以及流程有哪些？

> 组成部分	

1. Broker:消息队列服务进程，此进程包括两个部分：Exchange和Queue
2. Exchange：消息队列交换机，按一定的规则将消息路由转发到某个队列，对消息进行过滤
3. Queue：消息队列，存储消息的队列，消息到达队列并转发给指定的消费方
4. producer：消息生产者，即生产方客户端，生产方客户端将消息发送到Mq
5. Comuser：消息消费者，即消息方客户端，接受Mq转发的请求

> 流程	

- 发送消息
  1. 生产者与broker建立tcp连接
  2. 生产者与broker建立通道 channel
  3. 生产者通过通道将消息发送给broker，由Exchange将消息转发
  4. Exchange将消息转发到指定的queue
- 接收消息：
  1. 消费者和broker建立tcp连接
  2. 消费者和broker建立通道
  3. 消费者监听指定的通道
  4. 当有消息到达queue时Broker默认将消息推送给消费者
  5. 消费者接收消息

#### RabbitMq有哪些工作模式？

1. work Queues(工作队列)：多个消费者重复消费一个队列中的消息
2. Publish/Subscribe 发布订阅：工作队列的进阶版，增加了交换机，可以有多个队列
3. Routing 路由：每个队列可以设置一个或多个Routingkey，交换机根据路由请求转发
4. topics 通配符：与routing类似，但不同的是topics使用的是通配符匹配，其中*匹配一个单词，#匹配多个或者0个单词
5. Heander header转发器：header取消了routingkey,使用header中的key/value匹配对列
6. RPC 远程过程调用：客户端远程调用服务端

#### 如何保证消息不被重复消费

1. 唯一 ID+指纹码机制,利用数据库主键去重
2. 利用 redis 的原子性去实现
3. 通过redis实现幂等性

> 唯一ID+指纹码机制

指纹码:我们的一些规则或者时间戳加别的服务给到的唯一信息码,它并不一定是我们系统生成的，基本都是由我们的业务规则拼接而来，但是一定要保证唯一性，然后就利用查询语句进行判断这个 id 是否存在数据库中,优势就是实现简单就一个拼接，然后查询判断是否重复；劣势就是在高并发时，如果是单个数据库就会有写入性能瓶颈当然也可以采用分库分表提升性能，但也不是我们最推荐的方式。

> Redis 原子性

利用 redis 执行 `setnx` 命令，天然具有幂等性。从而实现不重复消费  

> redis实现幂等性

**防重 Token 令牌**

**方案描述：**

针对客户端连续点击或者调用方的超时重试等情况，例如提交订单，此种操作就可以用 Token  的机制实现防止重复提交。简单的说就是调用方在调用接口的时候先向后端请求一个全局 ID（Token），请求的时候携带这个全局 ID  一起请求（Token 最好将其放到 Headers 中），后端需要对这个 Token 作为 Key，用户信息作为 Value 到 Redis  中进行键值内容校验，如果 Key 存在且 Value 匹配就执行删除命令，然后正常执行后面的业务逻辑。如果不存在对应的 Key 或 Value  不匹配就返回重复执行的错误信息，这样来保证幂等操作。

**使用限制：**

- 需要生成全局唯一 Token 串；
- 需要使用第三方组件 Redis 进行数据效验；

**主要流程：**

1. 服务端提供获取 Token 的接口，该 Token 可以是一个序列号，也可以是一个分布式 ID 或者 UUID 串。
2. 客户端调用接口获取 Token，这时候服务端会生成一个 Token 串。
3. 然后将该串存入 Redis 数据库中，以该 Token 作为 Redis 的键（注意设置过期时间）。
4. 将 Token 返回到客户端，客户端拿到后应存到表单隐藏域中。
5. 客户端在执行提交表单时，把 Token 存入到 Headers 中，执行业务请求带上该 Headers。
6. 服务端接收到请求后从 Headers 中拿到 Token，然后根据 Token 到 Redis 中查找该 key 是否存在。
7. 服务端根据 Redis 中是否存该 key 进行判断，如果存在就将该 key 删除，然后正常执行业务逻辑。如果不存在就抛异常，返回重复提交的错误信息。

**注意**，在并发情况下，执行 Redis 查找数据与删除需要保证原子性，否则很可能在并发下无法保证幂等性。其实现方法可以使用分布式锁或者使用 Lua 表达式来注销查询与删除操作。

> 代码片段

```java
@RestController
public class TokenController {
    @Autowired
    private RedisService redisService;
    @GetMapping("/users-anon/gettoken")
    public Map getToken(@RequestParam("url") String url) {
        Map<String,String> tokenMap = new HashMap();
        String tokenValue = UUID.randomUUID().toString();
        tokenMap.put(url + tokenValue, tokenValue);
        //把token放到redis中，使用分布式锁的方式
        redisService.set(url + tokenValue, tokenValue);
        return tokenMap;
    }
}
```

```java
@Slf4j
@Component
public class TokenInterceptor implements HandlerInterceptor {
    @Autowired
    private RedisService redisService;
    @Override
    public boolean preHandle(HttpServletRequest request, HttpServletResponse response, Object handler) throws Exception {
        String tokenName = request.getRequestURI() + request.getParameter("token_value");
        String tokenValue = request.getParameter("token_value");
        if (tokenValue != null && !tokenValue.equals("")) {
            log.info("tokenName:{},tokenValue:{}",tokenName,tokenValue);
            return handleToken(request,response,handler);
        }
        return false;
    }

    @Override
    public void postHandle(HttpServletRequest request, HttpServletResponse response, Object handler, @Nullable ModelAndView modelAndView) throws Exception {
        if (redisService.exists(request.getParameter("token_value"))) {
            RedisTool.releaseDistributedLock(redisService, request.getParameter("token_value"), request.getParameter("token_value"));
        }
    }

    @Override
    public void afterCompletion(HttpServletRequest request, HttpServletResponse response, Object handler, @Nullable Exception ex) throws Exception {

    }

    /**
     * 分布式锁处理
     * @param request
     * @param response
     * @param handler
     * @return
     * @throws Exception
     */
    private boolean handleToken(HttpServletRequest request, HttpServletResponse response, Object handler) throws Exception {
        //当大量高并发下所有带token参数的请求进来时，进行分布式锁定,允许某一台服务器的一个线程进入，锁定时间3分钟
        if (RedisTool.tryGetDistributedLock(redisService,request.getParameter("token_value"),request.getParameter("token_value"),180)) {
            if (redisService.exists(request.getRequestURI() + request.getParameter("token_value"))) {
                //当请求的url与token与redis中的存储相同时
                if (redisService.get(request.getRequestURI() + request.getParameter("token_value")).equals(request.getParameter("token_value"))) {
                    //放行的该线程删除redis中存储的token
                    redisService.del(request.getRequestURI() + request.getParameter("token_value"));
                    //放行
                    return true;
                }
            }
            //当请求的url与token与redis中的存储不相同时，解除锁定
            RedisTool.releaseDistributedLock(redisService,request.getParameter("token_value"),request.getParameter("token_value"));
            //进行拦截
            return false;
        }
        return false;
    }
```

#### 如何保证消息不丢失，进行可靠性传输？

1. 生产者丢失数据：RabbitMq提供事务机制和确认机制两种模式确保生产者不丢消息
   - 事务机制：若出现异常则事务回滚，发送成功则提交数据，缺点发送消息时同步阻塞等待发送结果，造成吞吐量下降
   - 确认机制：生产者将通道channel设置成confirm模式，每条消息被生成唯一的id，若发送成功，会发送个确认给生产者，若失败，也会发送一个Nack给生产者。Confirm模式最大的好处在于它是异步的，一旦发布消息，生产者就可以在等信道返回确认的同时继续发送下一条消息，当消息最终得到确认之后，生产者便可以通过回调方法来处理该确认消息。
2. 消息队列丢失数据：处理消息队列丢数据的情况，一般是开启持久化磁盘。持久化配置可以和生产者的 confirm 机制配合使用，在消息持久化磁盘后，再给生产者发送一个Ack信号。这样的话，如果消息持久化磁盘之前，即使rabbitMQ挂掉了，生产者也会因为收不到Ack信号而再次重发消息。
3. 消费者丢失数据：将自动确认信息更改为手动确认信息

#### 如何处理消息堆积的情况？

如几千万条数据在MQ里积压了七八个小时。

- 原因分析：
  - 消息堆积往往是生产者的生产速度与消费者的消费速度不匹配导致的。
  - 有可能就是消费者消费能力弱，渐渐地消息就积压了
  - 也有可能是因为消息消费失败反复复重试造成的
  - 也有可能是消费端出了问题，导致不消费了或者消费极其慢。若是有bug则处理bug。	

- 解决方法：
  - 临时扩容，快速处理积压的消息：
    1. 先修复comuser的问题，确保其恢复消费速度，然后将现有的comsumer都停掉
    2. 临时扩建原先N倍数量的queue，然后写一个临时分发数据的消费者程序，将该程序部署上去消费队列中积压的数据，消费之后不做任何耗时处理，直接均匀轮询写入临时建立好的 N 倍数量的 queue 中；
    3. 临时征用 N 倍的机器来部署 consumer，每个 consumer 消费一个临时 queue 的数据等快速消费完积压数据之后，恢复原先部署架构 ，重新用原先的consumer 机器消费消息。这种做法相当于临时将 queue 资源和 consumer 资源扩大 N 倍，以正常 N 倍速度消费。
  - 恢复队列中丢失的数据：若使用RabbitMq，并且设置了过期时间，当超过一定时间，数据就会被清理掉，导致数据的丢失。可以采用批量重导的方式，在流量低峰期，写个程序手动查询丢失的那部分，并将消息冲新送入mq中。
  - mq长时间未处理导致Mq写满的情况：这种是由于消息积压mq，扩建执行太慢了，只好使用“丢弃+重新导入的方案”，写一个程序，连接mq里消费消息，消费一个，丢弃一个，等在流量低峰期在重新查询导入。

#### 如何保证RabbitMq的高可用？

单机模式

> 普通集群模式

普通集群模式就是在多台机器上启动多个rabbitmq实例，每个机器启动一个。但是创建的queue只会放在一个rabbitmq实例上面，但是其他的实例都同步了这个queue的元数据。在你消费的时候，如果连接到了另一个实例，他会从拥有queue的那个实例获取消息然后再返回给你。

<img src="https://cdn.jsdelivr.net/gh/hxznh/images@main/image-20220911133434041.png" alt="image-20220911133434041" style="zoom: 50%;" />

这种方式并没有做到所谓消息的高可用，就是个普通的集群，这样还会导致要么消费者每次随机连接一个实例然后拉取数据，这样的话在实例之间会产生网络传输，增加系统开销，要么固定连接那个queue所在的实例消费，这样会导致单实例的性能瓶颈。

而且如果那个方queue的实例宕机了，会导致接下来其他实例都无法拉取数据；如果没有开启消息的持久化会丢失消息；就算开启了消息的持久化，消息不一定会丢，但是也要等这个实例恢复了，才可以继续拉取数据。

所以这个并没有提供高可用，这种方案只是提高了吞吐量，也就是让集群中多个节点来服务某个queue的读写操作。

> 镜像集群模式

这种模式，才是rabbitmq提供是真正的高可用模式，跟普通集群不一样的是，你创建的queue，无论元数据还是queue里面是消息数据都存在多个实例当中，然后每次写消息到queue的时候，都会自动把消息到多个queue里进行消息同步。

<img src="https://cdn.jsdelivr.net/gh/hxznh/images@main/image-20220911133505920.png" alt="image-20220911133505920" style="zoom:50%;" />

这种模式的好处在于，任何一台机器宕机了，其他的机器还可以使用。

坏处在于：

1. **性能消耗太大**，所有机器都要进行消息的同步，导致网络压力和消耗很大。
2. **没有扩展性可言**，如果有一个queue负载很重，就算加了机器，新增的机器还是包含了这个queue的所有数据，并没有办法扩展queue。

如何开启镜像集群模式：在控制台新增一个镜像集群模式的策略，指定的时候可以要求数据同步到所有节点，也可以要求同步到指定节点，然后在创建queue的时候，应用这个策略，就会自动将数据同步到其他的节点上面去了。

> 多活模式

多活模式（Federation），依赖RabbitMQ的federation插件实现异地数据复制的主流模式，上面提到远程(Shovel)模式配置非常复杂，所以一般实现异地集群都是使用双活或者多活模型实现。

优点 ：可以实现持续可靠的AMQP数据通信，多活模式的实际配置与应用非常简单。

#### 交换机无法根据自身的类型和路由键找到复合的条件队列时的处理方法？

设置mandatory=true，代表返回消息给生产者，设置mandatory=false，代表直接丢弃

#### 消费者得到消息队列数据的方式？

一种是推模式/订阅模式/投递模式（也叫push模式）

- 消费者调用channel.basicConsume方法订阅队列后，由RabbitMQ主动将消息推送给订阅队列的消费者
- 另一种是拉模式/检索模式（也叫pull模式），需要消费者调用channel.basicGet方法，主动从指定队列中拉取消息。

#### 消息基于什么传输的？

基于信道 channel。信道是建立在真实的TCP 连接内的虚拟连接，且每条 TCP 连接上的信道数量没有限制。 TCP 连接的创建和销毁开销较大，且并发数受系统资源限制，会造成性能瓶颈。所以RabbitMQ 使用信道 channel 的方式来传输数据，

#### 死信队列DLX

DLX也是一个正常的Exchange，和一般的Exchange没有任何区别。能在任何的队列上被指定，实际上就是设置某个队列的属性。当这个队列出现死信（dead message，就是没有任何消费者消费）的时候，RabbitMQ就会自动将这条消息重新发布到Exchange上去，进而被路由到另一个队列。可以监听这个队列中的消息作相应的处理。

消息变为死信的几种情况

- 消息被拒绝，同时requeue=false(不能重回队列)
- TTL过期
- 队列达到最大长度，无法添加

#### 延迟队列

存储对应的延迟信息，当消息被发送以后，并不想让消费者立刻拿到消息，而是等待特定时间后，消费者才能拿到这个消息进行消费。

#### 优先级队列	

优先级高的队列会先被消费，可以通过x-max-priority参数来实现。但是当消费速度大于生产速度且 Broker 没有堆积的情况下，优先级显得没有意义



## Kafka

### 高性能原因

1. kafka本身是分布式集群，同时又采用了分区技术，具有较高的并发度。
2. 数据可以顺序写入磁盘，Kafka 的 producer 生产数据，要写入到 log 文件中，写的过程是一直追加到文件末端，为顺序写。
3. 使用了零拷贝技术。



### 零拷贝

**零拷贝不是指0次复制而是指0次调用CPU消耗资源。**

总体来说，零拷贝是指将数据直接从磁盘文件复制到内核读取缓冲区，然后多个消费者可以共用一个缓冲区，然后DMA  引擎直接把数据从内核读取缓冲区传到消费者，全程都是DMA参与，从而消除CPU参与的数据复制消耗，也不需要经由应用程序之手，减少了内核空间和用户空间之间的上下文切换，同时也大大减少了数据复制的次数。


















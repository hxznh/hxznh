# 计算机网络

## 什么是网络协议，为什么要对网络协议分层　*

网络协议是计算机在通信过程中要遵循的一些约定好的规则。

网络分层的原因：

- 易于实现和维护，因为各层之间是独立的，层与层之间不会收到影响。
- 有利于标准化的制定

## 计算机网络的各层协议及作用　***

计算机网络体系可以大致分为一下三种，七层模型、五层模型和TCP/IP四层模型，一般面试能流畅回答出五层模型就可以了，表示层和会话层被问到的不多。

<img src="https://cdn.jsdelivr.net/gh/hxznh/images@main/image-20220809235921096.png" alt="image-20220809235921096" style="zoom: 67%;" />

- 应用层
  应用层的任务是通过应用进程之间的交互来完成特定的网络作用，常见的应用层协议有域名系统DNS，HTTP协议等。
- 表示层
  表示层的主要作用是数据的表示、安全、压缩。可确保一个系统的应用层所发送的信息可以被另一个系统的应用层读取。
- 会话层
  会话层的主要作用是建立通信链接，保持会话过程通信链接的畅通，同步两个节点之间的对话，决定通信是否被中断以及通信中断时决定从何处重新发送。。
- 传输层
  传输层的主要作用是负责向两台主机进程之间的通信提供数据传输服务。
  - 常见协议协议有传输控制协议TCP和用户数据协议UDP。
- 网络层
  网络层的主要作用是选择合适的网间路由和交换结点，确保数据及时送达。常见的协议有IP协议, ARP协议，ICMP协议。
- 数据链路层
  数据链路层的作用是在物理层提供比特流服务的基础上，建立相邻结点之间的数据链路，通过差错控制提供数据帧（Frame）在信道上无差错的传输，并进行各电路上的动作系列。
  - 常见协议有SDLC、HDLC、PPP等。
- 物理层
  物理层的主要作用是实现相邻计算机结点之间比特流的透明传输，并尽量屏蔽掉具体传输介质和物
  理设备的差异
  - 常见协议：IEEE 802.1A， IEEE 802.2 到 IEEE 802.11。

## 5类网络地址

1. A类地址
   ⑴ A类地址第1字节为网络地址，其它3个字节为主机地址。
   ⑵ A类地址范围：**1.0.0.1—126.155.255.254**
   ⑶ A类地址中的私有地址和保留地址：
   ① **10.X.X.X**是私有地址（所谓的私有地址就是在互联网上不使用，而被用在局域网络中的地址）。
   ② **127.X.X.X**是保留地址，用做循环测试用的。

2. B类地址
   ⑴ B类地址第1字节和第2字节为网络地址，其它2个字节为主机地址。
   ⑵ B类地址范围：**128.0.0.1—191.255.255.254**。
   ⑶ B类地址的私有地址和保留地址
   ① **172.16.0.0—172.31.255.255**是私有地址
   ② **169.254.X.X**是保留地址。如果你的IP地址是自动获取IP地址，而你在网络上又没有找到可用的DHCP服务器。就会得到其中一个IP。

3. C类地址
   ⑴ C类地址第1字节、第2字节和第3个字节为网络地址，第4个个字节为主机地址。另外第1个字节的前三位固定为110。
   ⑵ C类地址范围：**192.0.0.1—223.255.255.254**。
   ⑶ C类地址中的私有地址：
   **192.168.X.X**是私有地址。

4. D类地址
   ⑴ D类地址不分网络地址和主机地址，它的第1个字节的前四位固定为1110。
   ⑵ D类地址范围：**224.0.0.1—239.255.255.254

   **

5. E类地址
   ⑴ E类地址也不分网络地址和主机地址，它的第1个字节的前五位固定为11110。
   ⑵ E类地址范围：**240.0.0.1—255.255.255.254**

<img src="https://cdn.jsdelivr.net/gh/hxznh/images@main/image-20230314083640688.png" alt="image-2023031底层3640688" style="zoom: 67%;" />

为确保高效的路由选择，设计因特网的人对每种网络地址的前几位做了限制。例如，由于路由器知道A 类网络地址总是以0  打头，因此只需阅读地址的第一位，从而提高转发分组的速度。编址方案在此指出了A 类、B 类和C  类地址的差别。在接下来的几节中，我将首先讲述这种差别，然后介绍D类和E 类地址。(只有A 类、B 类和C 类地址可用于给网络中的主机编址。)
**A 类网络地址范围**
IP 编址方案设计师指出， A 类网络地址的第一个字节的第一位必须为0 ，这意味着A 类地址第一个字节的取值为0-127 。
请看下面的网络地址:
Oxxxxxxx
如果将余下的7 位都设置为0 ，然后将它们都设置为1 ，我们便可获得A 类网络地址的范围:
00000000 = 0
01111111 =127
因此， A 类网络地址第一个字节的取值范围为0-127 (但0 和127 不是有效的A 类网络地址号。稍后我将介绍保留地址)。
**B 类网络地址范围**
RFC 规定， B 类网络地址的第一个字节的第一位必须为1 ，且第二位必须为0。如果将余下的6位全部设置为0 ，再将它们全部设置为1 ，便可获得B 类网络地址的范围:
10000000 =128
10111111 =191
正如你看到的， B 类网络地址第一个字节的取值为128 -191 。

**C 类网络地址范围**
RFC规定， C 类网络地址的第一个字节的前两位必须为1 ，而第三位必须为0。我们可按前面的方法将二进制转换为十进制，以找出C 类网络地址的范围:
11000000 = 192
11011111 = 223
因此，如果IP 地址以192-223 打头，我们就可判定它是C 类IP 地址。
**D 类和E 类网络地址范围**
第一个字节为224-255 的地址被保留用于D 类和E 类网络。D 类(224-239 )用作组播地址，
而E 类( 240 一255 )用于科学用途

## DNS　***

DNS的定义：DNS的全称是domain name system，即域名系统。DNS是因特网上作为域名和IP地址相互映射的一个分布式数据库，能够使用户更方便的去访问互联网而不用去记住能够被机器直接读取的IP地址。比如大家访问百度，更多地肯定是访问www.baidu.com，而不是访问112.80.248.74，因为这几乎无规则的IP地址实在太难记了。DNS要做的就是将www.baidu.com解析成112.80.248.74。

域名服务器详解：https://bithachi.blog.csdn.net/article/details/105583806

### DNS是集群式的工作方式还是单点式的，为什么？

答案是集群式的，很容易想到的一个方案就是只用一个DNS服务器，包含了所有域名和IP地址的映射。尽管这种设计方式看起来很简单，但是缺点显而易见，如果这个唯一的DNS服务器出了故障，那么就全完了，因特网就几乎崩了。为了避免这种情况出现，DNS系统采用的是分布式的层次数据数据库模式，还有缓存的机制也能解决这种问题。

### DNS的工作流程

主机向本地域名服务器的查询一般是采用递归查询，而本地域名服务器向根域名的查询一般是采用迭代查询。

- 递归查询: 主机向本地域名发送查询请求报文，而本地域名服务器不知道该域名对应的IP地址时，本地域名会继续向根域名发送查询请求报文，不是通知主机自己向根域名发送查询请求报文。
- 迭代查询: 本地域名服务器向根域名发出查询请求报文后，根域名不会继续向顶级域名服务器发送查询请求报文，而是通知本地域名服务器向顶级域名发送查询请求报文。

> 简单来说，递归查询就是，小明问了小红一个问题，小红不知道，但小红是个热心肠，小红就去问小王了，小王把答案告诉小红后，小红又去把答案告诉了小明。迭代查询就是，小明问了小红一个问题，小红也不知道，然后小红让小明去问小王，小明又去问小王了，小王把答案告诉了小明。

1. 在浏览器中输入www.baidu.com域名，操作系统会先检查自己本地的hosts文件是否有这个域名的映射关系，如果有，就先调用这个IP地址映射，完成域名解析。
2. 如果hosts文件中没有，则查询本地DNS解析器缓存，如果有，则完成地址解析。
3. 如果本地DNS解析器缓存中没有，则去查找本地DNS服务器，如果查到，完成解析。
4. 如果没有，则本地服务器会向根域名服务器发起查询请求。根域名服务器会告诉本地域名服务器去查询哪个顶级域名服务器。
5. 本地域名服务器向顶级域名服务器发起查询请求，顶级域名服务器会告诉本地域名服务器去查找哪个权限域名服务器。
6. 本地域名服务器向权限域名服务器发起查询请求，权限域名服务器告诉本地域名服务器www.baidu.com所对应的IP地址。
   7. 本地域名服务器告诉主机www.baidu.com所对应的IP地址。

## 了解ARP协议吗?　**

ARP协议属于**网络层**的协议，主要作用是实现从IP地址转换为MAC地址。在每个主机或者路由器中都建有一个ARP缓存表，表中有IP地址及IP地址对应的MAC地址。先来看一下什么是IP地址和MAC地址。

- **IP地址**：IP地址是指互联网协议地址，IP地址是IP协议提供的一种统一的地址格式，它为互联网上的每一个网络和每一台主机分配一个逻辑地址，以此来屏蔽物理地址的差异。
- **MAC地址**：MAC地址又称物理地址，由网络设备制造商生产时写在硬件内部，不可更改，并且每个以太网设备的MAC地址都是唯一的。

数据在传输过程中，会先从高层传到底层，然后在通信链路上传输。从下图可以看到TCP报文在网络层会被封装成IP数据报，在数据链路层被封装成MAC帧，然后在通信链路中传输。在网络层使用的是IP地址，在数据据链路层使用的是MAC地址。MAC帧在传送时的源地址和目的地址使用的都是MAC地址，在通信链路上的主机或路由器也都是根据MAC帧首部的MAC地址接收MAC帧。并且在**数据链路层是看不到IP地址**的，只有当数据传到网络层时去掉MAC帧的首部和尾部时才能在IP数据报的首部中找到源IP地址和目的地址。

<img src="https://cdn.jsdelivr.net/gh/hxznh/images@main/image-20220905090133670.png" alt="image-20220905090133670" style="zoom: 50%;" />

网络层实现的是主机之间的通信，而链路层实现的是链路之间的通信，所以从下图可以看出，在数据传输过程中，IP数据报的源地址(IP1)和目的地址(IP2)是一直不变的，而MAC地址(硬件地址)却一直随着链路的改变而改变。

<img src="https://cdn.jsdelivr.net/gh/hxznh/images@main/image-20220905090221628.png" alt="image-20220905090221628" style="zoom:50%;" />

> ARP的工作流程(面试时问ARP协议主要说这个就可以了)：

1. 在局域网内，主机A要向主机B发送IP数据报时，首先会在主机A的ARP缓存表中查找是否有IP地址及其对应的MAC地址，如果有，则将MAC地址写入到MAC帧的首部，并通过局域网将该MAC帧发送到MAC地址所在的主机B。
2. 如果主机A的ARP缓存表中没有主机B的IP地址及所对应的MAC地址，主机A会在局域网内广播发送一个ARP请求分组。局域网内的所有主机都会收到这个ARP请求分组。
3. 主机B在看到主机A发送的ARP请求分组中有自己的IP地址，会像主机A以单播的方式发送一个带有自己MAC地址的响应分组。
4. 主机A收到主机B的ARP响应分组后，会在ARP缓存表中写入主机B的IP地址及其IP地址对应的MAC地址。
5. 如果主机A和主机B不在同一个局域网内，即使知道主机B的MAC地址也是不能直接通信的，必须通过路由器转发到主机B的局域网才可以通过主机B的MAC地址找到主机B。并且主机A和主机B已经可以通信的情况下，主机A的ARP缓存表中存的并不是主机B的IP地址及主机B的MAC地址，而是主机B的IP地址及该通信链路上的下一跳路由器的MAC地址。这就是上图中的源IP地址和目的IP地址一直不变，而MAC地址却随着链路的不同而改变。
6. 如果主机A和主机B不在同一个局域网，参考上图中的主机H1和主机H2，这时主机H1需要先广播找到路由器R1的MAC地址，再由R1广播找到路由器R2的MAC地址，最后R2广播找到主机H2的MAC地址，建立起通信链路。

## 有了IP地址，为什么还要用MAC地址？　**

简单来说，标识网络中的一台计算机，比较常用的就是IP地址和MAC地址，但计算机的IP地址可由用户自行更改，管理起来相对困难，而MAC地址不可更改，所以一般会把IP地址和MAC地址组合起来使用。具体是如何组合使用的在上面的ARP协议中已经讲的很清楚了。
那只用MAC地址不用IP地址可不可以呢？其实也是不行的，因为在最早就是MAC地址先出现的，并且当时并不用IP地址，只用MAC地址，后来随着网络中的设备越来越多，整个路由过程越来越复杂，便出现了子网的概念。对于目的地址在其他子网的数据包，路由只需要将数据包送到那个子网即可，这个过程就是上面说的ARP协议。

那为什么要用IP地址呢？是因为IP地址是和地域相关的，对于同一个子网上的设备，IP地址的前缀都是一样的，这样路由器通过IP地 址的前缀就知道设备在在哪个子网上了，而只用MAC地址的话，路由器则需要记住每个MAC地址在哪个子网，这需要路由器有极大的存储空间，是无法实现的。

IP地址可以比作为地址，MAC地址为收件人，在一次通信过程中，两者是缺一不可的。

## 说一下ping的过程　**

ping是ICMP(网际控制报文协议)中的一个重要应用，ICMP是网络层的协议。ping的作用是测试两个主机的连通性。

ping的工作过程：

1. 向目的主机发送多个ICMP回送请求报文
2. 根据目的主机返回的回送报文的时间和成功响应的次数估算出数据包往返时间及丢包率。

路由器和交换机的区别？　*

|        | 所属网络模型的层级 | 功能                                                         |
| ------ | ------------------ | ------------------------------------------------------------ |
| 路由器 | 网络层             | 识别IP地址并根据IP地址转发数据包，维护数据表并基于数据表进行 最佳路径选择 |
| 交换机 | 数据链路层         | 识别MAC地址并根据MAC地址转发数据帧                           |

## TCP与UDP有什么区别　  ***

|      | 是否面向连接 | 可靠性  | 传输形式   | 传输效率 | 消耗资源 | 应用场景      | 首部字节 |
| ---- | ------------ | ------- | ---------- | -------- | -------- | ------------- | -------- |
| TCP  | 面向连接     | 可靠    | 字节流     | 慢       | 多       | 文件/邮件传输 | 20~60    |
| UDP  | 无连接       | 不可 靠 | 数据报文段 | 快       | 少       | 视频/输语音传 | 8        |

> 有时候面试还会问到TCP的首部都包含什么

- TCP首部(图片来源于网络)：
  前20个字节是固定的，后面有4n个字节是根据需而增加的选项，所以TCP首部最小长度为20字节。

<img src="https://cdn.jsdelivr.net/gh/hxznh/images@main/image-20221002205328885.png" alt="image-20221002205328885" style="zoom:50%;" />

- UDP首部(图片来源于网络)：
  UDP的首部只有8个字节，源端口号、目的端口号、长度和校验和各两个字节。

<img src="https://cdn.jsdelivr.net/gh/hxznh/images@main/image-20221002205403631.png" alt="image-20221002205403631" style="zoom: 67%;" />

## TCP协议如何保证可靠传输　***

主要有校验和、序列号、超时重传、流量控制及拥塞避免等几种方法。

- 校验和：在发送算和接收端分别计算数据的校验和，如果两者不一致，则说明数据在传输过程中出现了差错，TCP将丢弃和不确认此报文段。
- 序列号：TCP会对每一个发送的字节进行编号，接收方接到数据后，会对发送方发送确认应答(ACK报文)，并且这个ACK报文中带有相应的确认编号，告诉发送方，下一次发送的数据从编号多少开始发。如果发送方发送相同的数据，接收端也可以通过序列号判断出，直接将数据丢弃。如果中间出现丢包，则ACK连续编号的最后一个编号

<img src="https://cdn.jsdelivr.net/gh/hxznh/images@main/image-20221002205544765.png" alt="image-20221002205544765" style="zoom:50%;" />

- 超时重传：在上面说了序列号的作用，但如果发送方在发送数据后一段时间内（可以设置重传计时器规定这段时间）没有收到确认序号ACK，那么发送方就会重新发送数据。

这里发送方没有收到ACK可以分两种情况，如果是发送方发送的数据包丢失了，接收方收到发送方重新发送的数据包后会马上给发送方发送ACK；如果是接收方之前接收到了发送方发送的数据包，
  而返回给发送方的ACK丢失了，这种情况，发送方重传后，接收方会直接丢弃发送方重传的数据包，然后再次发送ACK响应报文。

  如果数据被重发之后还是没有收到接收方的确认应答，则进行再次发送。此时，等待确认应答的时间将会以2倍、4倍的指数函数延长，直到最后关闭连接。

- 流量控制：如果发送端发送的数据太快，接收端来不及接收就会出现丢包问题。为了解决这个问题，TCP协议利用了滑动窗口进行了流量控制。在TCP首部有一个16位字段大小的窗口，窗口的大小就是接收端接收数据缓冲区的剩余大小。接收端会在收到数据包后发送ACK报文时，将自己的窗口大小填入ACK中，发送方会根据ACK报文中的窗口大小进而控制发送速度。如果窗口大小为零，发送方会停止发送数据。
- 拥塞控制：如果网络出现拥塞，则会产生丢包等问题，这时发送方会将丢失的数据包继续重传，网络拥塞会更加严重，所以在网络出现拥塞时应注意控制发送方的发送数据，降低整个网络的拥塞程度。拥塞控制主要有四部分组成：慢开始、拥塞避免、快重传、快恢复，如下图(图片来源于网络)。

<img src="https://cdn.jsdelivr.net/gh/hxznh/images@main/image-20221002210215682.png" alt="image-20221002210215682" style="zoom: 50%;" />

这里的发送方会维护一个拥塞窗口的状态变量，它和流量控制的滑动窗口是不一样的，滑动窗口是根据接收方数据缓冲区大小确定的，而拥塞窗口是根据网络的拥塞情况动态确定的，一般来说发送方真实的发送窗口为滑动窗口和拥塞窗口中的最小值。

1. 慢开始：为了避免一开始发送大量的数据而产生网络阻塞，会先初始化cwnd为1，当收到ACK后到下一个传输轮次，cwnd为2，以此类推成指数形式增长。

2. 拥塞避免：因为cwnd的数量在慢开始是指数增长的，为了防止cwnd数量过大而导致网络阻塞，会设置一个慢开始的门限值ssthresh，当cwnd>=ssthresh时，进入到拥塞避免阶段，cwnd每个传输轮次加1。但网络出现超时，会将门限值ssthresh变为出现超时cwnd数值的一半，cwnd重新设置为1，如上图，在第12轮出现超时后，cwnd变为1，ssthresh变为12。

3. 快重传：在网络中如果出现超时或者阻塞，则按慢开始和拥塞避免算法进行调整。但如果只是丢失某一个报文段，如下图(图片来源于网络)，则使用快重传算法。

   <img src="https://cdn.jsdelivr.net/gh/hxznh/images@main/image-20221002210437851.png" alt="image-20221002210437851" style="zoom:50%;" />

   从上图可知，接收方正确地接收到M1和M2，而M3丢失，由于没有接收到M3，在接收方收到M5、M6和M7时，并不会进行确认，也就是不会发送ACK。这时根据前面说的保证TCP可靠性传输中的序列号的作用，接收方这时不会接收M5，M6，M7，接收方可以什么都不会，因为发送方长时间未收到M3的确认报文，会对M3进行重传。除了这样，接收方也可以重复发送M2的确认报文，这样发送端长时间未收到M3的确认报文也会继续发送M3报文。
   但是根据快重传算法，要求在这种情况下，需要快速向发送端发送M2的确认报文，在发送方收到三个M2的确认报文后，无需等待重传计时器所设置的时间，可直接进行M3的重传，这就是快重传。(面试时说这一句就够了，前面是帮助理解)

   4. 快恢复：从上上图圈4可以看到，当发送收到三个重复的ACK，会进行快重传和快恢复。快恢复是指将ssthresh设置为发生快重传时的cwnd数量的一半，而cwnd不是设置为1而是设置为为门限值ssthresh，并开始拥塞避免阶段。

## TCP的三次握手及四次挥手　***

> 必考题

在介绍三次握手和四次挥手之前，先介绍一下TCP头部的一些常用字段。

- 序号：seq，占32位，用来标识从发送端到接收端发送的字节流。
- 确认号：ack，占32位，只有ACK标志位为1时，确认序号字段才有效，ack=seq+1。
- 标志位：
  - SYN：发起一个新连接。
  - FIN：释放一个连接。
  - ACK：确认序号有效。

### 三次握手

> 三次握手的本质就是确定发送端和接收端具备收发信息的能力，在能流畅描述三次握手的流程及其中的字段含义作用的同时还需要记住每次握手时接收端和发送端的状态。这个比较容易忽略。

先看一张很经典的图（图片来源于网络），发送端有CLOSED、SYN-SENT、ESTABLISHED三种状态，接收端有CLOSED、LISTEN、SYN-RCVD、ESTABLISHED四种状态

<img src="https://cdn.jsdelivr.net/gh/hxznh/images@main/image-20221002221003482.png" alt="image-20221002221003482" style="zoom:50%;" />

假设发送端为客户端，接收端为服务端。开始时客户端和服务端的状态都是CLOSE。

- 第一次握手：客户端向服务端发起建立连接请求，客户端会随机生成一个起始序列号x，客户端向服务端发送的字段中包含标志位SYN=1，序列号seq=100。第一次握手前客户端的状态为CLOSE，第一次握手后客户端的状态为SYN-SENT。此时服务端的状态为LISTEN
- 第二次握手：服务端在收到客户端发来的报文后，会随机生成一个服务端的起始序列号y，然后给客户端回复一段报文，其中包括标志位SYN=1，ACK=1，序列号seq=y，确认号ack=x+1。第二次握手前服务端的状态为LISTEN，第二次握手后服务端的状态为SYN-RCVD，此时客户端的状态为SYN-SENT。（其中SYN=1表示要和客户端建立一个连接，ACK=1表示确认序号有效）
- 第三次握手：客户端收到服务端发来的报文后，会再向服务端发送报文，其中包含标志位ACK=1，序列号seq=x+1，确认号ack=y+1。第三次握手前客户端的状态为SYN-SENT，第三次握手后客户端和服务端的状态都为ESTABLISHED。

> 需要注意的一点是，第一次握手，客户端向服务端发起建立连接报文，会占一个序列号。但是第三次握手，同样是客户端向服务端发送报文，这次却不占序列号，所以建立连接后，客户端向服务端发送的第一个数据的序列号为x+1。

### 四次挥手

和三次握手一样，先看一张非常经典的图（图片来源于网络），客户端在四次挥手过程中有ESTABLISHED、FIN-WAIT-1、FIN-WAIT-2、TIME-WAIT、CLOSED等五个状态，服务端有ESTABLISHED、CLOSE-WAIT、LAST-ACK、CLOSED等四种状态。最好记住每次挥手时服务端和客户端的状态。



<img src="https://cdn.jsdelivr.net/gh/hxznh/images@main/image-20221002222322797.png" alt="image-20221002222322797" style="zoom:50%;" />

注： MSL(Max Segement Lifetime)

假设客户端首先发起的断开连接请求

- 第一次挥手：客户端向服务端发送的数据完成后，向服务端发起释放连接报文，报文包含标志位FIN=1，序列号seq=u。此时客户端只能接收数据，不能向服务端发送数据。
- 第二次挥手：服务端收到客户端的释放连接报文后，向客户端发送确认报文，包含标志位ACK=1，序列号seq=v，确认号ack=u+1。此时客户端到服务端的连接已经释放掉，客户端不能像服务端发送数据，服务端也不能向客户端发送数据。但服务端到客户端的单向连接还能正常传输数据。
- 第三次挥手：服务端发送完数据后向客户端发出连接释放报文，报文包含标志位FIN=1，标志位ACK=1，序列号seq=w，确认号ack=u+1。
- 第四次挥手：客户端收到服务端发送的释放连接请求，向服务端发送确认报文，包含标志位ACK=1，序列号seq=u+1，确认号ack=w+1。

### 为什么TCP连接的时候是3次？两次是否可以？

不可以，主要从以下两方面考虑（假设客户端是首先发起连接请求）：

1. 假设建立TCP连接仅需要两次握手，那么如果第二次握手时，服务端返回给客户端的确认报文丢失了，客户端这边认为服务端没有和他建立连接，而服务端却以为已经和客户端建立了连接，并且可能向服务端已经开始向客户端发送数据，但客户端并不会接收这些数据，浪费了资源。如果是三次握手，不会出现双方连接还未完全建立成功就开始发送数据的情况。
2. **防止已失效的连接请求报文又到达服务器**： 如果服务端接收到了一个早已失效的来自客户端的连接请求报文，会向客户端发送确认报文同意建立TCP连接。但因为客户端并不需要向服务端发送数据，所以此次TCP连接没有意义并且浪费了资源

### 为什么TCP连接的时候是3次，关闭的时候却是4次？

因为需要确保通信双方都能通知对方释放连接，假设客服端发送完数据向服务端发送释放连接请求，但客户端并不知道，服务端是否已经发送完数据，所以此次断开的是客服端到服务端的单向连接，服务端返回给客户端确认报文后，服务端还能继续单向给客户端发送数据。当服务端发送完数据后还需要向客户端发送释放连接请求，客户端返回确认报文，TCP连接彻底关闭。所以断开TCP连接需要客户端和服务端分别通知对方并分别收到确认报文，一共需要四次。

### TIME_WAIT和CLOSE_WAIT的区别在哪?

默认客户端首先发起断开连接请求

- 从上图可以看出，CLOSE_WAIT是被动关闭形成的，当客户端发送FIN报文，服务端返回ACK报文后进入CLOSE_WAIT。
- TIME_WAIT是主动关闭形成的，当第四次挥手完成后，客户端进入TIME_WAIT状态。

#### TIME_WAIT 数量过多怎么办

短时间后，所有的 `TIME_WAIT` 全都消失，被回收，端口包括服务，均正常。

即，在高并发的场景下，`TIME_WAIT` 连接存在，属于正常现象。

线上场景中，持续的高并发场景

- 一部分 `TIME_WAIT` 连接被回收，但新的 `TIME_WAIT` 连接产生；
- 一些极端情况下，会出现**大量**的 `TIME_WAIT` 连接。

> 上述大量的 `TIME_WAIT` 状态 TCP 连接，有什么业务上的影响吗？

Nginx 作为反向代理时，大量的短链接，可能导致 Nginx 上的 TCP 连接处于 `time_wait` 状态：

- 每一个 time_wait 状态，都会占用一个「本地端口」，上限为 `65535`(16 bit，2 Byte)；
- 当大量的连接处于 `time_wait` 时，新建立 TCP 连接会出错，**address already in use : connect** 异常

> 大量的 `TIME_WAIT` 状态 TCP 连接存在，其本质原因是什么？

- 大量的**短连接**存在
- 特别是 HTTP 请求中，如果 `connection` 头部取值被设置为 `close` 时，基本都由「**服务端**」发起**主动关闭连接**
- 而，`TCP 四次挥手`关闭连接机制中，为了保证 `ACK 重发`和 `丢弃延迟数据`，设置 `time_wait` 为 2 倍的 `MSL`（报文最大存活时间）

TIME_WAIT 状态：

- TCP 连接中，**主动关闭连接**的一方出现的状态；（收到 FIN 命令，进入 TIME_WAIT 状态，并返回 ACK 命令）
- 保持 2 个 `MSL` 时间，即，`4 分钟`；（MSL 为 2 分钟）

> 解决办法

解决上述 `time_wait` 状态大量存在，导致新连接创建失败的问题，一般解决办法：

1、**客户端**，HTTP 请求的头部，connection 设置为 keep-alive，保持存活一段时间：现在的浏览器，一般都这么进行了 2、**服务器端**，

- 允许 `time_wait` 状态的 socket 被**重用**
- 缩减 `time_wait` 时间，设置为 `1 MSL`（即，2 mins）

### 为什么客户端发出第四次挥手的确认报文后要等2MSL的时间才能释放TCP连接？

MSL(Max Segement Lifetime)的意思是报文的最长寿命，可以从两方面考虑：

1. 客户端发送第四次挥手中的报文后，再经过2MSL，可使本次TCP连接中的所有报文全部消失，不会出现在下一个TCP连接中。
2. **考虑丢包问题**：如果第四挥手发送的报文在传输过程中丢失了，那么服务端没收到确认ack报文就会重发第三次挥手的报文。如果客户端发送完第四次挥手的确认报文后直接关闭，而这次报文又恰好丢失，则会造成服务端无法正常关闭。

### 如果已经建立了连接，但是客户端突然出现故障了怎么办？

如果TCP连接已经建立，在通信过程中，客户端突然故障，那么服务端不会一直等下去，过一段时间就关闭连接了。

具体原理是TCP有一个保活机制，主要用在服务器端，用于检测已建立TCP链接的客户端的状态，防止因客户端崩溃或者客户端网络不可达，而服务器端一直保持该TCP链接，占用服务器端的大量资源(因为Linux系统中可以创建的总TCP链接数是有限制的)。

**保活机制原理**：设置TCP保活机制的保活时间keepidle(keepalive)，即在TCP链接超过该时间没有任何数据交互时，发送保活探测报文；设置保活探测报文的发送时间间隔keepInterval；设置保活探测报文的总发送次数keepCount。如果在keepCount次的保活探测报文均没有收到客户端的回应，则服务器端即关闭与客户端的TCP链接。

具体细节看这篇博客[TCP通信过程中异常情况整理](https://blog.csdn.net/yyc1023/article/details/80242815)

RST: Reset the connection

### 长连接有什么缺点

https://blog.csdn.net/weixin_46727129/article/details/120908715?utm_medium=distribute.pc_relevant.none-task-blog-2~default~baidujs_baidulandingword~default-0-120908715-blog-103307923.pc_relevant_recovery_v2&spm=1001.2101.3001.4242.1&utm_relevant_index=3

## Server端易受到SYN攻击？

## 

    服务器端的资源分配是在二次握手时分配的，而客户端的资源是在完成三次握手时分配的，所以服务器容易受到SYN洪泛攻击，SYN攻击就是Client在短时间内伪造大量不存在的IP地址，并向Server不断地发送SYN包，Server则回复SYN+ACK确认包，并等待Client确认回复ACK,而这些大量的IP是不存在的，并不会向服务端发送ack确认包，所以会大量的占领半连接队列资源，导致正常的SYN请求因为队列满而被丢弃，从而引起网络拥塞甚至系统瘫痪。

## 预防SYN攻击？

1. 开启SYN cookies技术
2. 增加最大半连接数量
3. 缩短超时时间。
4. 过滤网关防护

SYN cookies应用于linux、FreeBSD等操作系统，当半连接队列满时，SYNcookies并不丢弃SYN请求，而是通过加密技术来标识半连接状态。

在TCP实现中，当收到客户端的SYN请求时，服务器需要回复SYN＋ACK包给客户端，客户端也要发送确认包给服务器。通常，服务器的初始序列号由服务器按照一定的规律计算得到或采用随机数，但在SYN cookies中，服务器的初始序列号是通过对客户端IP地址、客户端端囗、服务器IP地址和服务器端囗以及其他一些安全数值等要素进行hash运算，加密得到的，称之为cookie。当服务器遭受SYN攻击使得半连接状态队列满时，服务器并不拒绝新的SYN请求，而是回复cookie（回复包的SYN序列号）给客户端， 如果收到客户端的ACK包，服务器将客户端的ACK序列号减去1得到cookie比较值，并将上述要素进行一次hash运算，看看是否等于此cookie。如果相等，直接完成三次握手（注意：此时并不用查看此连接是否属于半连接状态队列）。

> 过滤网关防护

这里，过滤网关主要指明防火墙，当然路由器也能成为过滤网关。防火墙部署在不同网络之间，防范外来非法攻击和防止保密信息外泄，它处于客户端和服务器之间

### SYN cookies

![img](https://cdn.jsdelivr.net/gh/hxznh/images@main/20210927223705271.png)

- 如上图，TCP建立连接过程中，服务端在**第二次握手后**会将连接放入半连接队列中。然后在第三次握手成功后，从半连接队列中移除加入到全连接队列中。
- 如果没有开启syn cookie，则当半连接队列满了之后，再有新的连接就会直接丢弃。
- 当开启了syn cookie后，就可以在**不使用syn半连接队列的情况下成功建立连接**
- 具体方法：
  - 服务器收到**syn请求(第一次握手)**后，会根据当前状态计算出一个cookie值。放在**syn+ack报文(第二次握手)**中发出。
  - 当客户端返回**ack报文(第三次握手)**时会再次带上这个cookie值。服务端取出这个值进行验证。如果合法就认为连接建立成功。加入全连接队列中。

## HTTP 与 HTTPS 的区别　***

|              | HTTP               | HTTPS                                   |
| ------------ | ------------------ | --------------------------------------- |
| 端口         | 80                 | 443                                     |
| 安全性       | 无加密，安全性较差 | 有加密机制，安全性较高                  |
| 资源消耗     | 较少               | 由于加密处理，资源消耗更多              |
| 是否需要证书 | 不需要             | 需要                                    |
| 协议         | 运行在TCP协议之上  | 运行在SSL协议之上，SSL运行在TCP协议之上 |

## SSL/TSL 是什么？

这两实际上是⼀个东⻄。

SSL 是洋⽂ “==Secure Sockets Layer==” 的缩写，中⽂叫做「安全套接层」。它是在上世纪 90 年代中期，由⽹景公司
设计的。

到了1999年， SSL 因为应⽤⼴泛，已经成为互联⽹上的事实标准。 IETF 就在那年把 SSL 标准化。标准化之后的名
称改为 TLS（是 “==Transport Layer Security==” 的缩写），中⽂叫做 「传输层安全协议」。

很多相关的⽂章都把这两者并列称呼（SSL/TLS），因为这两者可以视作同⼀个东⻄的不同阶段。  

## 什么是对称加密与非对称加密　**

- 对称加密
  对称加密指加密和解密使用同一密钥，优点是运算速度快，缺点是如何安全将密钥传输给另一方。
  常见的对称加密算法有DES、AES等等。

- 非对称加密
  非对称加密指的是加密和解密使用不同的密钥，一把公开的公钥，一把私有的私钥。公钥加密的信息只有私钥才能解密，私钥加密的信息只有公钥才能解密。优点解决了对称加密中存在的问题。缺点是运算速度较慢。常见的非对称加密算法有RSA、DSA、ECC等等。

  非对称加密的工作流程：A生成一对非对称密钥，将公钥向所有人公开，B拿到A的公钥后使用A的公钥对信息加密后发送给A，经过加密的信息只有A手中的私钥能解密。这样B可以通过这种方式将自己的公钥加密后发送给A，两方建立起通信，可以通过对方的公钥加密要发送的信息，接收方用自己的私钥解密信息。

## HTTPS的加密过程　＊＊＊

上面已经介绍了对称加密和非对称加密的优缺点，HTTPS是将两者结合起来，使用的对称加密和非对称加密的混合加密算法。具体做法就是使用非对称加密来传输对称密钥来保证安全性，使用对称加密来保证通信的效率。

简化的工作流程：服务端生成一对非对称密钥，将公钥发给客户端。客户端生成对称密钥，用服务端发来的公钥进行加密，加密后发给服务端。服务端收到后用私钥进行解密，得到客户端发送的对称密钥。通信双方就可以通过对称密钥进行高效地通信了。

但是仔细想想这其中存在一个很大地问题，就是客户端最开始如何判断收到的这个公钥就是来自服务端而不是其他人冒充的？

这就需要证书上场了，服务端会向一个权威机构申请一个证书来证明自己的身份，到时候将证书（证书中包含了公钥）发给客户端就可以了，客户端收到证书后既证明了服务端的身份又拿到了公钥就可以进行下一步操作了。

HTTPS的加密过程：

1. 客户端向服务端发起第一次握手请求，告诉服务端客户端所支持的SSL的指定版本、加密算法及密钥长度等信息。
2. 服务端将自己的公钥发给数字证书认证机构，数字证书认证机构利用自己的私钥对服务器的公钥进行数字签名，并给服务器颁发公钥证书。
3. 服务端将证书和公钥发给客户端。
4. 客户端利用数字认证机构的公钥，向数字证书认证机构验证公钥证书上的数字签名，确认服务器公开密钥的真实性。
5. 客户端使用服务端的公开密钥加密自己生成的对称密钥，发给服务端。
6. 服务端收到后利用私钥解密信息，获得客户端发来的对称密钥。
7. 通信双方可用对称密钥来加密解密信息。

上述流程存在的一个问题是客户端哪里来的数字认证机构的公钥，其实，在很多浏览器开发时，会内置常数字证书认证机构的公钥。
流程图如下：

<img src="https://cdn.jsdelivr.net/gh/hxznh/images@main/image-20221002231633452.png" alt="image-20221002231633452" style="zoom: 50%;"/>



## 常用HTTP状态码　***

这也是一个面试经常问的题目,背下来就行了

| 状态码 |       类别       |
| :----: | :--------------: |
|  1XX   |    信息状态码    |
|  2XX   |    成功状态码    |
|  3XX   |   重定向状态码   |
|  4XX   | 客户端错误状态码 |
|  5XX   | 服务端错误状态码 |

常见的HTTP状态码

- 1XX
  - 100 Continue：表示正常，客户端可以继续发送请求
  - 101 Switching Protocols：切换协议，服务器根据客户端的请求切换协议。
- 2XX
  - 200 OK：请求成功
  - 201 Created：已创建，表示成功请求并创建了新的资源
  - 202 Accepted：已接受，已接受请求，但未处理完成。
  - 204 No Content：无内容，服务器成功处理，但未返回内容。
  - 205 Reset Content：重置内容，服务器处理成功，客户端应重置文档视图。
  - 206 Partial Content：表示客户端进行了范围请求，响应报文应包含Content-Range指定范围的实体内容
- 3XX
  - 301 Permanently Moved：永久性重定向
  - 302 Temporarily Moved：临时重定向
  - 303 See Other：和301功能类似，但要求客户端采用get方法获取资源
  - 304 Not Modified：所请求的资源未修改，服务器返回此状态码时，不会返回任何资源。
  - 305 Use Proxy：所请求的资源必须通过代理访问
  - 307 Temporary Redirect： 临时重定向，与302类似，要求使用get请求重定向。
- 4XX
  - 400 Bad Request：客户端请求的语法错误，服务器无法理解。
  - 401 Unauthorized：表示发送的请求需要有认证信息。
  - 403 Forbidden：服务器理解用户的请求，但是拒绝执行该请求
  - 404 Not Found：服务器无法根据客户端的请求找到资源。
  - 405 Method Not Allowed：客户端请求中的方法被禁止
  - 406 Not Acceptable：服务器无法根据客户端请求的内容特性完成请求
  - 底层 Request Time-out：服务器等待客户端发送的请求时间过长，超时
- 5XX
  - 500 Internal Server Error：服务器内部错误，无法完成请求
  - 501 Not Implemented：服务器不支持请求的功能，无法完成请求

## 常见的HTTP方法　***

| 方法    | 作用                                                    |
| ------- | ------------------------------------------------------- |
| GET     | 获取资源                                                |
| POST    | 传输实体主体                                            |
| PUT     | 上传文件                                                |
| DELETE  | 删除文件                                                |
| HEAD    | 和GET方法类似，但只返回报文首部，不返回报文实体主体部分 |
| PATCH   | 对资源进行部分修改                                      |
| OPTIONS | 查询指定的URL支持的方法                                 |
| CONNECT | 要求用隧道协议连接代理                                  |
| TRACE   | 服务器会将通信路径返回给客户端                          |

为了方便记忆，可以将PUT、DELETE、POST、GET理解为客户端对服务端的增删改查。

- PUT：上传文件，向服务器添加数据，可以看作增
- DELETE：删除文件
- POST：传输数据，向服务器提交数据，对服务器数据进行更新。
- GET：获取资源，查询服务器资源

## GET和POST区别　***

- 作用
  GET用于获取资源，POST用于传输实体主体
- 参数位置
  GET的参数放在URL中，POST的参数存储在实体主体中，并且GET方法提交的请求的URL中的数据最多是2048字节，POST请求没有大小限制。
- 安全性
  GET方法因为参数放在URL中，安全性相对于POST较差一些
- 幂等性
  GET方法是具有幂等性的，而POST方法不具有幂等性。这里幂等性指客户端连续发出多次请求，收到的结果都是一样的.



## HTTP 1.0、HTTP 1.1及HTTP 2.0的主要区别是什么　**

> HTTP 1.0和HTTP 1.1的区别

- 长连接
  HTTP 1.1默认使用长连接和请求的流水线操作。长连接是指不在需要每次请求都重新建立一次连接，HTTP 1.0默认使用短连接，每次请求都要重新建立一次TCP连接，资源消耗较大。在双方没有明确提出断开连接时，一直保持连接。

- 流水线

  请求的流水线操作是指客户端在收到HTTP的响应报文之前可以先发送新的请求报文。 **但服务端必须按照收到客户端请求的先后顺序依次回送响应结果，以保证客户端能够区分出每个请求的响应内容。**

  HTTP1.0不支持请求的流水线操作,需要等到收到HTTP的响应报文后才能继续发送新的请求报文。

- 缓存处理
  在HTTP 1.0中主要使用header中的If-Modified-Since,Expires作为缓存判断的标准，HTTP 1.1引入了Entity tag，If-Unmodified-Since, If-Match等更多可供选择的缓存头来控制缓存策略。

- 新增状态码
  在HTTP 1.1新增了24个状态响应码，

  如支持请求资源的某个部分，返回206；

  100 Continue：用于客户端在发送Post数据给服务器前，征询服务器意见是否愿意处理数据。一般在数据量较大(>1024Byte)的情况下使用。客户端接受到100Continue的回应后，才会继续发送数据。

- HOST域
  在HTTP 1.0 中认为每台服务器都会绑定唯一的IP地址，所以，请求中的URL并没有传递主机名。但后来一台服务器上可能存在多个虚拟机，它们共享一个IP地址，所以HTTP 1.1中请求消息和响应消息都应该支持Host域。

- 带宽优化及网络连接的使用
  在HTTP 1.0中会存在浪费带宽的现象，主要是因为不支持断点续传功能，客户端只是需要某个对象的一部分，服务端却将整个对象都传了过来。在HTTP 1.1中请求头引入了range头域，它支持只请求资源的某个部分，返回的状态码为206。

## HTTP 2.0

### 浏览器阻塞（HOL blocking）：

浏览器对于同一个域名，一般PC端浏览器会针对单个域名的server同时建立6～8个连接，手机端的连接数则一般控制在4～6个（这个根据浏览器内核不同可能会有所差异），超过浏览器最大连接数限制，后续请求就会被阻塞。

> 在讲HTTP/2之前我们先来说说SPDY

SPDY协议是Google提出的基于传输控制协议(TCP)的应用层协议，通过压缩、多路复用和优先级来缩短加载时间。该协议是一种更加快速的内容传输协议，于2009 年年中发布。

GoogleChrome、MozillaFirefox以及Opera已默认开启SPDY。Google曾经称它的测试显示，页面载入提高了一倍。该协议是一种更加快速的内容传输协议。



### SPDY协议设定的目标

1. 页面加载时间（PLT，Page • Load Time）降低 50%；
2. 无需网站作者修改任何内容；
3. 最小化配置复杂度，无需变更网络基础设施；

注：为了达到降低50% 页面加载时间的目标，SPDY 引入了一个新的二进制分帧数据层，以实现多向请求和响应、优先次序、最小化及消除不必要的网络延迟，目的是更有效地利用底层TCP 连接；

**HTTP/2：SPDY的升级版**

- HTTP-WG（HTTP Working Group）在2012 年初把HTTP 2.0提到了议事日程，吸取SPDY 的经验教训，并在此基础上制定官方标准。
- HTTP/2 的主要目标是改进传输性能，更有效地利用网络资源，实现低延迟和高吞吐量。从另一方面看，HTTP 的高层协议语义并不会因为这次版本升级而受影响。所有HTTP 首部、值，以及它们的使用场景都不会变。
- HTTP/2 致力于突破上一代标准众所周知的性能限制，但它也是对之前1.x 标准的扩展，而非替代。之所以要递增一个大版本到2.0，主要是因为它改变了客户端与服务器之间交换数据的方式

**HTTP/2 是如何提高效率呢？**

**二进制分帧：HTTP 2.0 的所有帧都采用二进制编码**

- **帧**：客户端与服务器通过交换帧来通信，帧是基于这个新协议通信的最小单位。
- **消息**：是指逻辑上的 HTTP 消息，比如请求、响应等，由一或多个帧组成。
- **流**：流是连接中的一个虚拟信道，可以承载双向的消息；每个流都有一个唯一的整数标识符（1、2…N）；

### HTTP 2.0的新特性

- 新的二进制格式：HTTP 1.x的解析是基于文本，HTTP 2.0的解析采用二进制，实现方便，健壮性更好。
- 多路复用：每一个request对应一个id，一个连接上可以有多个request，每个连接的request可以随机混在一起，这样接收方可以根据request的id将request归属到各自不同的服务端请求里。
- header压缩：在HTTP 1.x中，header携带大量信息，并且每次都需要重新发送，HTTP 2.0采用编码的方式减小了header的大小，同时通信双方各自缓存一份header fields表，避免了header的重复传输。
  - HPACK 算法：在客户端和服务器同时维护⼀张头信息表，所有字段都会存⼊这个表，⽣成⼀个索引号，以后就不发送同样字段了，只发送索引号，这样就提⾼速度了。  
- 服务端推送：客户端在请求一个资源时，会把相关资源一起发给客户端，这样客户端就不需要再次发起请求。

> 服务端推送

- 服务器可以对一个客户端请求发送多个响应。服务器向客户端推送资源无需客户端明确地请求。
- HTTP 2.0 连接后，客户端与服务器交换SETTINGS 帧，借此可以限定双向并发的流的最大数量。
- 所有推送的资源都遵守同源策略。换句话说，服务器不能随便将第三方资源推送给客户端，而必须是经过双方确认才行。
- 服务器必须遵循请求- 响应的循环，只能借着对请求的响应推送资源

> 服务器推送到底是什么？

服务端推送能把客户端所需要的资源伴随着index.html一起发送到客户端，省去了客户端重复请求的步骤。正因为没有发起请求，建立连接等操作，所以静态资源通过服务端推送的方式可以极大地提升速度。

**普通的客户端请求过程：**

<img src="https://cdn.jsdelivr.net/gh/hxznh/images@main/026e037f8272e98d578b67e0a06b5071.jpeg" alt="img" style="zoom: 67%;" />

服务端推送请求过程：

<img src="https://cdn.jsdelivr.net/gh/hxznh/images@main/60d69bb492aa4d8a90e35227f0081901.png" alt="img" style="zoom:67%;" />

## HTTP2.0的多路复用和HTTP1.X中的长连接复用有什么区别？

- HTTP/1.0 一次请求-响应，建立一个连接，用完关闭；每一个请求都要建立一个连接；
- HTTP/1.1 Pipeling解决方式为：服务器若干个请求排队串行化单线程处理，后面的请求等待前面请求的返回才能获得执行机会，一旦有某请求超时等，后续请求只能被阻塞，毫无办法，也就是人们常说的队头阻塞；
- HTTP/2多个请求可同时在一个连接上并行执行。某个请求任务耗时严重，不会影响到其它连接的正常执行；

## HTTP/2 有哪些缺陷？  

HTTP/2 主要的问题在于，多个 HTTP 请求在复⽤⼀个 TCP 连接，下层的 TCP 协议是不知道有多少个 HTTP 请求的。所以⼀旦发⽣了丢包现象，就会触发 TCP 的重传机制，这样在⼀个 TCP 连接中的所有的 HTTP 请求都必须等待这个丢了的包被重传回来。

- HTTP/1.1 中的管道（ pipeline）传输中如果有⼀个请求阻塞了，那么队列后请求也统统被阻塞住了

- HTTP/2 多个请求复⽤⼀个TCP连接，⼀旦发⽣丢包，就会阻塞住所有的 HTTP 请求。

这都是基于 TCP 传输层的问题，所以 HTTP/3 把 HTTP 下层的 TCP 协议改成了 UDP！  

## HTTP/3

<img src="https://cdn.jsdelivr.net/gh/hxznh/images@main/image-20230407130633110.png" alt="image-20230407130633110" style="zoom: 50%;" />

UDP 发⽣是不管顺序，也不管丢包的，所以不会出现 HTTP/1.1 的队头阻塞 和 HTTP/2 的⼀个丢包全部重传问
题。
⼤家都知道 UDP 是不可靠传输的，但基于 UDP 的 QUIC 协议 可以实现类似 TCP 的可靠性传输。

- QUIC 有⾃⼰的⼀套机制可以保证传输的可靠性的。当某个流发⽣丢包时，只会阻塞这个流， 其他流不会受到
  影响。

- TLS3 升级成了最新的 1.3 版本，头部压缩算法也升级成了 QPack 。
- HTTPS 要建⽴⼀个连接，要花费 6 次交互，先是建⽴三次握⼿，然后是 TLS/1.3 的三次握⼿。 QUIC 直接
  把以往的 TCP 和 TLS/1.3 的 6 次交互合并成了 3 次，减少了交互次数。  

<center><img src="%E5%BA%95%E5%B1%82.assets/image-20230407130802336.png" alt="image-20230407130802336" style="zoom:50%;" /></center>

所以， QUIC 是⼀个在 UDP 之上的伪 TCP + TLS + HTTP/2 的多路复⽤的协议。

QUIC 是新协议，对于很多⽹络设备，根本不知道什么是 QUIC，只会当做 UDP，这样会出现新的问题。所以HTTP/3 现在普及的进度⾮常的缓慢，不知道未来 UDP 是否能够逆袭 TCP。  

## Session、Cookie和Token的主要区别　＊＊＊

HTTP协议是无状态的，即服务器无法判断用户身份。Session和Cookie可以用来进行身份辨认

- Cookie
  Cookie是保存在客户端一个小数据块，其中包含了用户信息。当客户端向服务端发起请求，服务端会像客户端浏览器发送一个Cookie，客户端会把Cookie存起来，当下次客户端再次请求服务端时，会携带上这个Cookie，服务端会通过这个Cookie来确定身份。
- Session
  Session是通过Cookie实现的，和Cookie不同的是，Session是存在服务端的。当客户端浏览器第一次访问服务器时，服务器会为浏览器创建一个sessionid，将sessionid放到Cookie中，存在客户端浏览器。比如浏览器访问的是购物网站，将一本《图解HTTP》放到了购物车，当浏览器再次访问服务器时，服务器会取出Cookie中的sessionid，并根据sessionid获取会话中的存储的信息，确认浏览器的身份是上次将《图解HTTP》放入到购物车那个用户。
- Token
  客户端在浏览器第一次访问服务端时，服务端生成的一串字符串作为Token发给客户端浏览器，下次浏览器在访问服务端时携带token即可无需验证用户名和密码，省下来大量的资源开销。看到这里很多人感觉这不是和sessionid作用一样吗？其实是不一样的，但是本文章主要针对面试，知识点很多，篇幅有限，几句话也解释不清楚，
- 具体参考这篇文章 [cookie、session与token的真正区别](https://blog.csdn.net/whl190412/article/details/90024671)

| 存放位置 | 占用空间     | 安全性 | 应用场景 |                    |
| -------- | ------------ | ------ | -------- | ------------------ |
| Cookie   | 客户端浏览器 | 小     | 较低     | 一般存放配置信息   |
| Session  | 服务端       | 多     | 较高     | 存放较为重要的信息 |

### Token被盗如何保证用户信息安全？

Token授权机制：
 用户使用用户名密码登录后服务器给客户端返回一个Token（通常是UUID），并将Token-UserId以键值对的形式存放在缓存服务器中。

服务端接收到请求后进行Token验证，如果Token不存在，说明请求无效。Token是客户端访问服务端的凭证。

时间戳超时机制：
 用户每次请求都带上当前时间的时间戳timestamp，服务端接收到timestamp后跟当前时间进行比对，

如果时间差大于一定时间（比如5分钟），则认为该请求失效。时间戳超时机制是防御DOS攻击的有效手段。

签名机制：
 将 Token 和 时间戳 加上其他请求参数再用MD5或SHA-1算法（可根据情况加点盐）加密，加密后的数据就是本次请求的签名sign，

服务端接收到请求后以同样的算法得到签名，并跟当前的签名进行比对，如果不一样，说明参数被更改过，直接返回错误标识。

## 如果客户端禁止 cookie 能实现 session 还能用吗？　*

可以，Session的作用是在服务端来保持状态，通过sessionid来进行确认身份，但sessionid一般是通过Cookie来进行传递的。如果Cooike被禁用了，可以通过在URL中传递sessionid。

## 在浏览器中输⼊url地址到显示主页的过程 ***

> 面试超高频的一道题，一般能说清楚流程就可以。

1. 对输入到浏览器的url进行DNS解析，将域名转换为IP地址。
2. 和目的服务器建立TCP连接
3. 向目的服务器发送HTTP请求
4. 服务器处理请求并返回HTTP报文
5. 浏览器解析并渲染页面

## Servlet是线程安全的吗　＊

Servlet不是线程安全的，多线程的读写会导致数据不同步的问题。




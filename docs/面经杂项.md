## 零拷贝原理

在实际应用中，如果我们需要把磁盘中的某个文件内容发送到远程服务器上，那么它必须要经过几个拷贝的过程，如图。

1. 从磁盘中读取目标文件内容拷贝到内核缓冲区
2. CPU 控制器再把内核缓冲区的数据赋值到用户空间的缓冲区中
3. 接着在应用程序中，调用 write()方法，把用户空间缓冲区中的数据拷贝到内核下
   的 Socket Buffer 中。
4. 最后，把在内核模式下的 SocketBuffer 中的数据赋值到网卡缓冲区（NIC Buffer)
5. 网卡缓冲区再把数据传输到目标服务器上  

<img src="%E9%9D%A2%E7%BB%8F%E6%9D%82%E9%A1%B9.assets/image-20230822232645584.png" alt="image-20230822232645584" style="zoom:67%;" />

这个过程中我们可以发现，数据从磁盘到最终发送出去，要经历 4 次拷贝，而在这四次拷贝过程中，有两次拷贝是浪费的，分别是：

1. 从内核空间赋值到用户空间

2. 从用户空间再次复制到内核空间
   除此之外，由于用户空间和内核空间的切换会带来 CPU 的上线文切换，对于 CPU 性能也会造成性能影响。  

而零拷贝，就是把这两次多于的拷贝省略掉，应用程序可以直接把磁盘中的数据从内核中直接传输给 Socket，而不需要再经过应用程序所在的用户空间，如下图所示。
零拷贝通过DMA（Direct Memory Access）技术把文件内容复制到内核空间中的ReadBuffer，
接着把包含数据位置和长度信息的文件描述符加载到 Socket Buffer 中，DMA 引擎直接可以把数据从内核空间中传递给网卡设备。
在这个流程中，数据只经历了两次拷贝就发送到了网卡中，并且减少了 2 次 cpu 的上下文切换，对于效率有非常大的提高。  

<img src="%E9%9D%A2%E7%BB%8F%E6%9D%82%E9%A1%B9.assets/image-20230822232855160.png" alt="image-20230822232855160" style="zoom:67%;" />

所以，所谓零拷贝，并不是完全没有数据赋值，只是相对于用户空间来说，不再需要进行数据拷贝。对于前面说的整个流程来说，零拷贝只是减少了不必要的拷贝次数而已。

> 在程序中如何实现零拷贝呢？

- 在 Linux 中，零拷贝技术依赖于底层的 sendfile()方法实现
- 在 Java 中，FileChannal.transferTo() 方法的底层实现就是 sendfile() 方法。

除此之外，还有一个 mmap 的文件映射机制

它的原理是：将磁盘文件映射到内存, 用户通过修改内存就能修改磁盘文件。使用这种方式可以获取很大的 I/O 提升，省去了用户空间到内核空间复制的开销。  

## innoDB 如何解决幻读  

Mysql 有四种事务隔离级别，这四种隔离级别代表当存在多个事务并发冲突时，可能出
现的脏读、不可重复读、幻读的问题。
其中 InnoDB 在 RR 的隔离级别下，解决了幻读的问题。  

| 隔离级别                  | 脏读   | 不可重复读 | 幻读   |
| ------------------------- | ------ | ---------- | ------ |
| 未提交读(Read Uncommited) | 允许   | 允许       | 允许   |
| 提交读(Read Ccommited)    | 不允许 | 允许       | 允许   |
| 可重复读(Repeatable Read) | 不允许 | 不允许     | 允许   |
| 串行化                    | 不允许 | 不允许     | 不允许 |

> 什么是幻读？

那么， 什么是幻读呢？
幻读是指在同一个事务中，前后两次查询相同的范围时，得到的结果不一致

- 第一个事务里面我们执行了一个范围查询，这个时候满足条件的数据只有一条
- 第二个事务里面，它插入了一行数据，并且提交了
- 接着第一个事务再去查询的时候，得到的结果比第一查询的结果多出来了一条数据。  

所以，幻读会带来数据一致性问题。

> InnoDB 如何解决幻读的问题

InnoDB 引入了间隙锁和 next-key Lock 机制来解决幻读问题，为了更清晰的说明这两
种锁，我举一个例子：
假设现在存在这样（图片）这样一个 B+ Tree 的索引结构，这个结构中有四个索引元
素分别是：1、4、7、10。  

<img src="%E9%9D%A2%E7%BB%8F%E6%9D%82%E9%A1%B9.assets/image-20230822233627340.png" alt="image-20230822233627340" style="zoom:67%;" />

当我们通过主键索引查询一条记录，并且对这条记录通过 for update 加锁

```mysql
select * from user where id = 1 for update;
```

被锁定的记录在锁释放之前，其他事务无法对这条记录做任何操作。

前面我说过对幻读的定义： 幻读是指在同一个事务中，前后两次查询相同的范围时，得到的结果不一致！
注意，这里强调的是**范围查询**，

也就是说，InnoDB 引擎要解决幻读问题，必须要保证一个点，就是如果一个事务通过这样一条语句（如图）进行锁定时。  

```mysql
select * from user where id > 4 and id < 7 for update;
```

另外一个事务再执行这样一条（显示图片）insert 语句，需要被阻塞，直到前面获得锁
的事务释放  

```mysql
insert into user(id, name) values(5, 'zjz');
```

所以，在 InnoDB 中设计了一种间隙锁，它的主要功能是锁定一段范围内的索引记录（如图）

当对查询范围 id>4 and id <7 加锁的时候，会针对 B+树中（4，7）这个开区间范围的索引加间隙锁。
意味着在这种情况下，其他事务对这个区间的数据进行插入、更新、删除都会被锁住。  

<img src="%E9%9D%A2%E7%BB%8F%E6%9D%82%E9%A1%B9.assets/image-20230822234107658.png" alt="image-20230822234107658" style="zoom: 50%;" />

但是，还有另外一种情况，比如像这样（图片）  

```mysql
select * from user where id > 4 for update;
```

这条查询语句是针对 id>4 这个条件加锁，那么它需要锁定多个索引区间，所以在这种
情况下 InnoDB 引入了 next-key Lock 机制。
next-key Lock 相当于间隙锁和记录锁的合集，记录锁锁定存在的记录行，间隙锁锁住
记录行之间的间隙，而 next-key Lock 锁住的是两者之和。（如图所示）  

<img src="%E9%9D%A2%E7%BB%8F%E6%9D%82%E9%A1%B9.assets/image-20230822234223984.png" alt="image-20230822234223984" style="zoom: 50%;" />

每个数据行上的非唯一索引列上都会存在一把 next-key lock，当某个事务持有该数据行的 next-key lock 时，会锁住一段左开右闭区间的数据。

因此，当通过 id>4 这样一种范围查询加锁时，会加 next-key Lock，锁定的区间范围是：(4, 7] , (7,10],(10,+∞]  

<img src="%E9%9D%A2%E7%BB%8F%E6%9D%82%E9%A1%B9.assets/image-20230822234326897.png" alt="image-20230822234326897" style="zoom: 67%;" />

间隙锁和 next-key Lock 的区别在于加锁的范围，间隙锁只锁定两个索引之间的引用间隙，而 next-key Lock 会锁定多个索引区间，它包含记录锁和间隙锁。  

当我们使用了范围查询，不仅仅命中了 Record 记录，还包含了 Gap 间隙，在这种情况下我们使用的就是临键锁，它是 MySQL 里面默认的行锁算法。

> 总结

虽然 InnoDB 中通过间隙锁的方式解决了幻读问题，但是加锁之后一定会影响到并发性能，因此，如果对性能要求较高的业务场景中，可以把隔离级别设置成 RC，这个级别中不存在间隙锁。


## CPU 飙高系统反应慢怎么排查？  

1. CPU 是整个电脑的核心计算资源，对于一个应用进程来说，CPU 的最小执行单元是线程。  

2. 导致 CPU 飙高的原因有几个方面

   1. CPU 上下文切换过多，对于 CPU 来说，同一时刻下每个 CPU 核心只能运行一个线程，如果有多个线程要执行，CPU 只能通过上下文切换的方式来执行不同的线程。上下文切换需要做两个事情

      - 保存运行线程的执行状态
      - 让处于等待中的线程执行

      这两个过程需要 CPU 执行内核相关指令实现状态保存，如果较多的上下文切换会占据大量 CPU 资源，从而使得 cpu 无法去执行用户进程中的指令，导致响应速度下降。在 Java 中，文件 IO、网络 IO、锁等待、线程阻塞等操作都会造成线程阻塞从而触发上下文切换

      2. CPU 资源过度消耗，也就是在程序中创建了大量的线程，或者有线程一直占用CPU 资源无法被释放，比如死循环！
         CPU 利用率过高之后，导致应用中的线程无法获得 CPU 的调度，从而影响程序的执行效率！

3. 既然是这两个问题导致的 CPU 利用率较高，于是我们可以通过 top 命令，找到 CPU利用率较高的进程，在通过 Shift+H 找到进程中 CPU 消耗过高的线程，这里有两种情况。

   1. CPU 利用率过高的线程一直是同一个，说明程序中存在线程长期占用 CPU 没有释放的情况，这种情况直接通过 jstack 获得线程的 Dump 日志，定位到线程日志后就可以找到问题的代码。
      2. CPU 利用率过高的线程 id 不断变化，说明线程创建过多，需要挑选几个线程id，通过 jstack 去线程 dump 日志中排查。

4. 最后有可能定位的结果是程序正常，只是在 CPU 飙高的那一刻，用户访问量较大，导致系统资源不够  



## Dubbo 的服务请求失败怎么处理？  

Dubbo 是一个 RPC 框架，它为我们的应用提供了远程通信能力的封装，同时，Dubbo在 RPC 通信的基础上，逐步在向一个生态在演进，它涵盖了服务注册、动态路由、容错、服务降级、负载均衡等能力，基本上在微服务架构下面临的问题，Dubbo 都可以解决。

而对于 Dubbo 服务请求失败的场景，默认提供了重试的容错机制，也就是说，如果基于 Dubbo 进行服务间通信出现异常，服务消费者会对服务提供者集群中其他的节点发起重试，确保这次请求成功，默认的额外重试次数是 2 次。除此之外，Dubbo 还提供了更多的容错策略，我们可以根据不同的业务场景来进行选择。

1. 快速失败策略，服务消费者只发起一次请求，如果请求失败，就直接把错误抛出去。这种比较适合在非幂等性场景中使用
2. 失败安全策略，如果出现服务通信异常，直接把这个异常吞掉不做任何处理
3. 失败自动恢复策略，后台记录失败请求，然后通过定时任务来对这个失败的请求进行重发。
4. 并行调用多个服务策略，就是把这个消息广播给服务提供者集群，只要有任何一个节点返回，就表示请求执行成功。
5. 广播调用策略，逐个调用服务提供者集群，只要集群中任何一个节点出现异常，就表示本次请求失败  

要注意的是，默认基于重试策略的容错机制中，需要注意幂等性的处理，否则在事务型的操作中，容易出现多次数据变更的问题。  



## 请说一下网络四元组  

元组，简单理解就是在 TCP 协议中，去确定一个客户端连接的组成要素，它包括源IP 地址、目标 IP 地址、源端口号、目标端口号。
正常情况下，我们对于网络通信的认识可能是这样（如图）。
服务端通过 ServerSocket 建立一个对指定端口号的监听，比如 8080。 客户端通过目标 ip 和端口就可以和服务端建立一个连接，然后进行数据传输。  

<img src="%E9%9D%A2%E7%BB%8F%E6%9D%82%E9%A1%B9.assets/image-20230823000552390.png" alt="image-20230823000552390" style="zoom:67%;" />

但是我们知道的是，一个 Server 端可以接收多个客户端的连接，比如像这种情况（如图）。
那，当多个客户端连接到服务端的时候，服务端需要去识别每一个连接。  

<img src="%E9%9D%A2%E7%BB%8F%E6%9D%82%E9%A1%B9.assets/image-20230823000607085.png" alt="image-20230823000607085" style="zoom:67%;" />

并且(如图），TCP 是全双工协议，也就是说数据允许在连接的两个方向上同时传输，因此这里的客户端，如果是反向通信，它又变成了服务端。  

<img src="%E9%9D%A2%E7%BB%8F%E6%9D%82%E9%A1%B9.assets/image-20230823000618216.png" alt="image-20230823000618216" style="zoom:67%;" />

所以基于这两个原因，就引入了四元组的设计，也就是说，当一个客户端和服务端建立一个 TCP 连接的时候，通过源 IP 地址、目标 IP 地址、源端口号、目标端口号来确定一个唯一的 TCP 连接。因为服务器的 IP 和端口是不变的，只要客户端的 IP 和端口彼此不同就 OK 了。
比如像这种情况（如图），同一个客户端主机上有三个连接连到 Server 端，那么这个时候源 IP 相同，源端口号不同。此时建立的四元组就是（10.23.15.3，59461 ，192.168.8.135，8080）
其中，源端口号是每次建立连接的时候系统自动分配的。  

<img src="%E9%9D%A2%E7%BB%8F%E6%9D%82%E9%A1%B9.assets/image-20230823000634720.png" alt="image-20230823000634720" style="zoom:67%;" />

## Spring Boot 中自动装配机制的原理  

自动装配，简单来说就是自动把第三方组件的 Bean 装载到 Spring IOC 器里面，不需
要开发人员再去写 Bean 的装配配置。
在 Spring Boot 应用里面，只需要在启动类加上@SpringBootApplication 注解就可以实现自动装配。  

@SpringBootApplication 是一个复合注解，真正实现自动装配的注解是@EnableAutoConfiguration。
（如图）自动装配的实现主要依靠三个核心关键技术。

1. 引入 Starter 启动依赖组件的时候，这个组件里面必须要包含@Configuration 配置类，在这个配置类里面通过@Bean 注解声明需要装配到 IOC 容器的 Bean 对象。
2. 这个配置类是放在第三方的 jar 包里面，然后通过 SpringBoot 中的约定优于配置思想，把这个配置类的全路径放在 classpath:/META-INF/spring.factories 文件中。这样 SpringBoot 就可以知道第三方 jar 包里面的配置类的位置，这个步骤主要是用到了 Spring 里面的 SpringFactoriesLoader 来完成的。
3. SpringBoot 拿到所第三方 jar 包里面声明的配置类以后，再通过 Spring 提供的ImportSelector 接口，实现对这些配置类的动态加载。
   SpringBoot 是约定优于配置这一理念下的产物，所以在很多的地方，都会看到这类的思想。它的出现，让开发人员更加聚焦在了业务代码的编写上，而不需要去关心和业务无关的配置。
   其实，自动装配的思想，在 SpringFramework3.x 版本里面的@Enable 注解，就有了实现的雏形。@Enable 注解是模块驱动的意思，我们只需要增加某个@Enable 注解，就自动打开某个功能，而不需要针对这个功能去做 Bean 的配置，@Enable 底层也是帮我们去自动完成这个模块相关 Bean 的注入。


![image-20230823105512637](%E9%9D%A2%E7%BB%8F%E6%9D%82%E9%A1%B9.assets/image-20230823105512637.png)



## 什么是 Dubbo？它有哪些核心功能？

Dubbo 是以高性能 RPC 框架，它提供了分布式架构下的服务之间通信方案，使得开发者可以不需要关心网络通信的细节。通过该框架可以使得远程服务调用方式和本地服务调用方式一样简单。
Dubbo 是一款高性能、轻量级的开源 RPC 框架。由 10 层模式构成，整个分层依赖由上至下。
通过这张图我们也可以将 Dubbo 理解为三层模式：  

<img src="%E9%9D%A2%E7%BB%8F%E6%9D%82%E9%A1%B9.assets/image-20230823110731510.png" alt="image-20230823110731510" style="zoom:67%;" />

第一层的 Business 业务逻辑层由我们自己来提供接口和实现还有一些配置信息。

第二层的 RPC 调用的核心层负责封装和实现整个 RPC 的调用过程、负载均衡、集群容错、代理等核心功能。

Remoting 则是对网络传输协议和数据转换的封装。

根据 Dubbo 官方文档的介绍，Dubbo 提供了六大核心能力

- 面向接口代理的高性能 RPC 调用。
- 智能容错和负载均衡。
- 服务自动注册和发现。
- 高度可扩展能力。
- 运行期流量调度。
- 可视化的服务治理与运维。  

## 详细说说 Dubbo 负载均衡的几种策略

Dubbo 有五种负载策略：  

1. 加权随机：假设我们有一组服务器 servers = [A, B, C]，他们对应的权重为weights = [5, 3, 2]，权重总和为 10。现在把这些权重值平铺在一维坐标值上，[0, 5) 区间属于服务器 A，[5, 8) 区间属于服务器 B，[8, 10) 区间属于服务器 C。接下来通过随机数生成器生成一个范围在 [0, 10) 之间的随机数，然后计算这个随机数会落到哪个区间上就可以了。
2. 最小活跃数：每个服务提供者对应一个活跃数 active，初始情况下，所有服务提供者活跃数均为 0。每收到一个请求，活跃数加 1，完成请求后则将活跃数减 1。在服务运行一段时间后，性能好的服务提供者处理请求的速度更快，因此活跃数下降的也越快，此时这样的服务提供者能够优先获取到新的服务请求。
3. 一致性 hash：通过 hash 算法，把 provider 的 invoke 和随机节点生成 hash，并将这个 hash 投射到 [0, 2^32 - 1] 的圆环上，查询的时候根据 key 进行 md5 然后进行 hash，得到第一个节点的值大于等于当前 hash 的 invoker。
4. 加权轮询：比如服务器 A、B、C 权重比为 5:2:1，那么在 8 次请求中，服务器 A 将收到其中的 5 次请求，服务器 B 会收到其中的 2 次请求，服务器 C 则收到其中的 1 次请求。
5. 最短响应时间权重随机：计算目标服务的请求的响应时间，根据响应时间最短的服务，配置更高的权重进行随机访问。  

## Dubbo 的工作原理是什么样的？  

1. 服务启动的时候，provider 和 consumer 根据配置信息，连接到注册中心 register，分别向注册中心注册和订阅服务

2. register 根据服务订阅关系，返回 provider 信息到 consumer，同时 consumer 会把 provider 信息缓存到本地。如果信息有变更，consumer 会收到来自 register 的推送 

3. consumer 生成代理对象，同时根据负载均衡策略，选择一台 provider，同时定时向monitor 记录接口的调用次数和时间信息

4. 拿到代理对象之后，consumer 通过代理对象发起接口调用

5. provider 收到请求后对数据进行反序列化，然后通过代理调用具体的接口实现

   

## Dubbo 与 Spring Cloud 的区别

Dubbo 是 SOA 时代的产物，它的关注点主要在于服务的调用，流量分发、流量监控和熔断。而 Spring Cloud 诞生于微服务架构时代，考虑的是微服务治理的方方面面，另外由于依托了 Spirng、Spirng Boot 的优势之上，两个框架在开始目标就不一致，Dubbo 定位服务治理、Spirng Cloud 是一个生态。  

两者最大的区别是 Dubbo 底层是使用 Netty 这样的 NIO 框架，是基于 TCP 协议传输的，配合以 Hession 序列化完成 RPC 通信。而 SpringCloud 是基于 Http 协议+Rest 接口调用远程过程的通信，相对来说，Http 请求会有更大的报文，占的带宽也会更多。但是 REST 相比 RPC 更为灵活，服务提供方和调用方的依赖只依靠一纸契约，不存在代码级别的强依赖  

## Mysql 优化

MySQL 的性能优化我认为可以分为 4 大部分

- 硬件和操作系统层面的优化
- 架构设计层面的优化
- MySQL 程序配置优化
- SQL 优化  

> 硬件及操作系统层面优化

从硬件层面来说，影响 Mysql 性能的因素有，CPU、可用内存大小、磁盘读写速度、网络带宽
从操作系层面来说，应用文件句柄数、操作系统网络的配置都会影响到 Mysql 性能。
这部分的优化一般由 DBA 或者运维工程师去完成。

在硬件基础资源的优化中，我们重点应该关注服务本身承载的体量，然后提出合理的指标要求，避免出现资源浪费！
架构设计层面的优化
MySQL 是一个磁盘 IO 访问量非常频繁的关系型数据库在高并发和高性能的场景中.MySQL 数据库必然会承受巨大的并发压力，而此时，我们的优化方式可以分为几个部分。

1. 搭建 Mysql 主从集群，单个 Mysql 服务容易单点故障，一旦服务器宕机，将会导致依赖 Mysql 数据库的应用全部无法响应。 主从集群或者主主集群可以保证服务的高可用性。
2. 读写分离设计，在读多写少的场景中，通过读写分离的方案，可以避免读写冲突导致的性能影响
3. 引入分库分表机制，通过分库可以降低单个服务器节点的 IO 压力，通过分表的方式可以降低单表数据量，从而提升 sql 查询的效率。
4. 针对热点数据，可以引入更为高效的分布式数据库，比如 Redis、MongoDB 等，他们可以很好的缓解 Mysql 的访问压力，同时还能提升数据检索性能。  

SQL 优化

SQL 优化又能分为三步曲

1. 慢 SQL 的定位和排查

   我们可以通过慢查询日志和慢查询日志分析工具得到有问题的 SQL 列表。

2. 执行计划分析
   针对慢 SQL，我们可以使用关键字 explain 来查看当前 sql 的执行计划.可以重点关注type key rows filterd 等字段 ，从而定位该 SQL 执行慢的根本原因。再有的放矢的进行优化
3. 第三、使用 show profile 工具
   Show Profile 是 MySQL 提供的可以用来分析当前会话中，SQL 语句资源消耗情况的工具，可用于 SQL 调优的测量。在当前会话中.默认情况下处于 show profile 是关闭状态，打开之后保存最近 15 次的运行结果  
   针对运行慢的 SQL，通过 profile 工具进行详细分析.可以得到 SQL 执行过程中所有的资源开销情况.如 IO 开销,CPU 开销,内存开销等.  

## Spring Bean 生命周期的执行流程  

Spring 生命周期全过程大致分为五个阶段：创建前准备阶段、创建实例阶段、依赖注入阶段、容器缓存阶段和销毁实例阶段。
这张是 Spring Bean 生命周期完整流程图，其中对每个阶段的具体操作做了详细介绍：  

1. 创建前准备阶段【干什么、作用】
   这个阶段主要的作用是，Bean 在开始加载之前，需要从上下文和相关配置中解析并查找 Bean 有关的扩展实现，
   比如像`init-method`-容器在初始化 bean 时调用的方法、`destory-method`，容器在销毁 bean 时调用的方法。
   以及，BeanFactoryPostProcessor 这类的 bean 加载过程中的前置和后置处理。
   这些类或者配置其实是 Spring 提供给开发者，用来实现 Bean 加载过程中的扩展机制，在很多和 Spring 集成的中间件中比较常见，比如 Dubbo。
2. 创建实例阶段
   这个阶段主要是通过反射来创建 Bean 的实例对象，并且扫描和解析 Bean 声明的一些属性。  
3. 依赖注入阶段
   如果被实例化的 Bean 存在依赖其他 Bean 对象的情况，则需要对这些依赖 bean 进行对象注入。比如常见的`@Autowired`、setter 注入等依赖注入的配置形式。
   同时，在这个阶段会触发一些扩展的调用，比如常见的扩展类：BeanPostProcessors（用来实现 bean 初始化前后的扩展回调）、InitializingBean（这个类有一个 afterPropertiesSet()，这个在工作中也比较常见）、BeanFactoryAware 等等。  
4. 容器缓存阶段
   容器缓存阶段主要是把 bean 保存到容器以及 Spring 的缓存中，到了这个阶段，Bean就可以被开发者使用了。
   这个阶段涉及到的操作，常见的有，`init-method`这个属性配置的方法， 会在这个阶段调用。
   以及像 BeanPostProcessors 方法中的后置处理器方法如：postProcessAfterInitialization，也会在这个阶段触发。  
5. 销毁实例阶段
   当 Spring 应用上下文关闭时，该上下文中的所有 bean 都会被销毁。
   如果存在 Bean 实现了 DisposableBean 接口，或者配置了`destory-method`属性，会在这个阶段被调用。  

## Spring 是如何解决循环依赖问题的？  

如果在代码中，将两个或多个 Bean 互相之间持有对方的引用就会发生循环依赖。循环的依赖将会导致注入死循环。这是 Spring 发生循环依赖的原因。

循环依赖有三种形态：  

第一种互相依赖：A 依赖 B，B 又依赖 A，它们之间形成了循环依赖。  

<img src="%E9%9D%A2%E7%BB%8F%E6%9D%82%E9%A1%B9.assets/image-20230823114933981.png" alt="image-20230823114933981" style="zoom:67%;" />

第二种三者间依赖：A 依赖 B，B 依赖 C，C 又依赖 A，形成了循环依赖.

<img src="%E9%9D%A2%E7%BB%8F%E6%9D%82%E9%A1%B9.assets/image-20230823115000388.png" alt="image-20230823115000388" style="zoom:67%;" />

第三种是自我依赖：A 依赖 A 形成了循环依赖。  

<img src="%E9%9D%A2%E7%BB%8F%E6%9D%82%E9%A1%B9.assets/image-20230823115015173.png" alt="image-20230823115015173" style="zoom:67%;" />

Spring 中设计了三级缓存来解决循环依赖问题，当我们去调用 getBean()方法的时候，Spring 会先从一级缓存中去找到目标 Bean，如果发现一级缓存中没有便会去二级缓存中去找，而如果一、二级缓存中都没有找到，意味着该目标 Bean 还没有实例化。

于是，Spring 容器会实例化目标 Bean（PS：刚初始化的 Bean 称为早期 Bean） 。然后，将目标 Bean 放入到二级缓存中，同时，加上标记是否存在循环依赖。如果不存在循环依赖便会将目标 Bean 存入到二级缓存，否则，便会标记该 Bean 存在循环依赖，然后将等待下一次轮询赋值，也就是解析@Autowired 注解。等@Autowired 注解赋值完成后（PS：完成赋值的 Bean 称为成熟 Bean） ，会将目标 Bean 存入到一级缓存。

Spring 一级缓存中存放所有的成熟 Bean，
二级缓存中存放所有的早期 Bean，先取一级缓存，再去二级缓存。  

<img src="%E9%9D%A2%E7%BB%8F%E6%9D%82%E9%A1%B9.assets/image-20230823115058705.png" alt="image-20230823115058705" style="zoom: 67%;" />

> 三级缓存的作用是什么？

三级缓存是用来存储代理 Bean，当调用 getBean()方法时，发现目标 Bean 需要通过代理工厂来创建，此时会将创建好的实例保存到三级缓存，最终也会将赋值好的 Bean同步到一级缓存中。  

> Spring 中哪些情况下，不能解决循环依赖问题？

1. 多例 Bean 通过 setter 注入的情况，不能解决循环依赖问题  

2. 构造器注入的 Bean 的情况，不能解决循环依赖问题
3. 单例的代理 Bean 通过 Setter 注入的情况，不能解决循环依赖问题
4. 设置了@DependsOn 的 Bean 的情况，不能解决循环依赖问题
   

## 什么是 RPC？

RPC 的概念与技术其实是比较早的，40 年前，也就是 1981 年由 Nelson 提出。1984年，Birrell 和把它用于分布式系统间的通讯。Java 在 1.1 版本提供了 Java 版本的 RPC框架（RMI）。
全称为 Remote Procedure Call，翻译过来就是远程过程调用，它是一种通过网络从远程计算机程序上请求服务，而不需要了解底层网络技术的协议，凡是符合该协议的框架，我们都可以称它为 RPC 框架。

关于 RPC 协议，通俗来讲就是，A 计算机提供一个服务，B 计算机可以像调用本地服务那样调用 A 计算机的服务。
要实现 RPC，需要通过网络传输数据，并对调用的过程进行封装。

现在比较流行的 RPC 框架，都会采用 TCP 作为底层传输协议。
RPC 强调的是过程调用，调用的过程对用户而言是是透明的，用户不需要关心调用的细节，可以像调用本地服务一样调用远程服务  

<img src="%E9%9D%A2%E7%BB%8F%E6%9D%82%E9%A1%B9.assets/image-20230823154115247.png" alt="image-20230823154115247" style="zoom:67%;" />

图所示，一个完整的 RPC 架构里面包含了四个核心的组件，分别是Client ,Server,Client Stub 以及 Server Stub：  

1. 客户端（Client），服务的调用方。
2. 服务端（Server），真正的服务提供者。
3. 客户端存根（Client Stub），存放服务端的地址消息，再将客户端的请求参数打包成网络消息，然后通过网络远程发送给服务方。
4. 服务端存根（Server Stub），接收客户端发送过来的消息，将消息解包，并调用本地的方法。

目前比较流行的开源 RPC 框架有 Google 的 gRPC，Facebook 的 Thrift，阿里巴巴的Dubbo  

## RPC 的运用场景和优势

在开发电商系统时，随着业务越来越复杂，走分布式架构这个方向是绝大部分互联网企业必然的选择。

分布式架构落地的里程碑，应该是阿里的去 IOE 运动的成功，它让互联网企业看到了，如何利用更少的软硬件成本来支撑海量的用户。

分布式架构的核心，就是利用多个普通计算机节点，组成一个庞大而复杂的计算网络，提供高性能以及高并发的能力支撑。

在分布式架构中，原本的单体应用被拆分成多个独立部署的服务分部在计算及网络上，这些服务必然需要通过网络进行数据交互。而 RPC 框架就是解决在分布式架构中的各个业务服务彼此的网络通信问题。一般来说，RPC 服务主要是针对大型的企业，也就说当我们业务复杂度以及用户量都比较高时，需要解耦服务，扩展性强、部署灵活一般市面上开源的 PRC 框架，除了提供基础的远程通信功能以外，还会在性能消耗、传输效率、服务治理等方面做很多的设计，比如阿里开源的 RPC 框架 Dubbo。  

## 分布式事务的原理  

分布式事务是指事务的参与者、支持事务的服务器、资源服务器以及事务管理器分别位于分布式系统的不同节点之上。
比如大型的电商系统中的下单场景，会涉及到扣库存、优惠促销计算、订单 ID 生成。

通常情况下，库存、促销、主键生成策略都位于不同的服务器和数据库表中。下单接口的成功与否，不仅取决于本地节点的数据库操作，而且还依赖第三方系统的结果，这时候分布式事务就保证这些操作要么全部成功，要么全部失败。

因此，本质上来说，分布式事务就是为了保证不同数据库的数据一致性。基于 CAP 定理可以知道，对于上述情况产生的分布式事务问题，我们要么采用强一致性方案、要么采用弱一致性方案。

- 所谓强一致性，就是指通过第三方的事务管理器来协调多个节点的事务，保证每个节点的事务达到同时成功和同时失败，为了实现这样一个需求，我们会引入 Xopen/DTP 模型提供的 XA 协议，基于 2pc 或者 3pc 的方式来实现。但是，在如果全局事务管理器中的多个节点中，如果任意一个节点再进行事务提交确认时，由于网络通信延迟导致阻塞，就会影响到所有节点事务的提交，而这个阻塞过程也会影响阻塞用户的请求线程，这对于用户体验以及整体性能的影响较大  

- 而弱一致性方案，就是针对强一致性方案所衍生出来性能和数据一致性平衡的一个方案，简单来说就是损失掉强一致性，数据在某一个时刻会存在不一致的状态，但是最终这些数据会达成一致。这样的好处是提升了系统的性能  

在弱一致性方案中，常见的解决方案：

1. 使用分布式消息队列，来实现最终一致性
2. 基于 TCC 事务，通过演进版本的二阶段提交实现最终一致性
3. 使用 Seata 事务框架，它提供了多种事务模式，如 AT、XA、Saga、TCC 等
   

## 实现分布式锁的解决方案中，你认为 Zookeeper 和 Redis 哪种更好？

> 为什么使用分布式锁？

使用分布式锁的目的，是为了保证同一时间只有一个 JVM 进程可以对共享资源进行操作。
根据锁的用途可以细分为以下两类：

- 允许多个客户端操作共享资源，我们称为共享锁  

  这种锁的一般是对共享资源具有幂等性操作的场景，主要是为了避免重复操作共享资源频繁加锁带来的性能开销。

- 只允许一个客户端操作共享资源，我们成为排他锁

  这种锁一般是用在对共享资源操作具有非幂等性操作的场景，也就是需要保证在同一时刻只有一个进程或者线程能够访问这个共享资源。

> 目前实现分布式锁最常用的中间件是 Redis 和 Zookeeper

第一种，Redis 可以通过两种方式来实现

1. 利用 Redis 提供的`SET key value NX PX milliseconds `指令，
   这个指令是设置一个 key-value，如果 key 已经存在，则返回 0，否则返 回 1，
   我们基于这个返回值来判断锁的占用情况从而实现分布式锁。  

基于 Redission 客户端来实现分布式锁，Redisson 提供了分布式锁的封装方法，我们只需要调用 api 中的`lock（）`和`unlock()`方法。它帮我们封装锁实现的细节和复杂度

- redisson 所有指令都通过 lua 脚本执行并支持 lua 脚本原子性执行
- redisson 中有一个 watchdog 的概念，翻译过来就是看门狗，它会在你获取锁之后，每隔 10 秒帮你把 key 的超时时间设为 30s，就算一直持有锁也不会出现 key过期了。“看门狗”的逻辑保证了没有死锁发生。

第二种，基于 ZK 实现分布式锁的落地方案  

Zookeeper 实现分布式锁的方法比较多，我们可以使用有序节点来实现  

<img src="%E9%9D%A2%E7%BB%8F%E6%9D%82%E9%A1%B9.assets/image-20230823154901933.png" alt="image-20230823154901933" style="zoom:67%;" />

> 两种方案都有各自的优缺点

对于 redis 的分布式锁而言，它有以下缺点：

- 它获取锁的方式简单粗暴，如果获取不到锁，会不断尝试获取锁，比较消耗性能。
- Redis 是 AP 模型，在集群模式中由于数据的一致性会导致锁出现问题，即便使用Redlock 算法来实现，在某些复杂场景下，也无法保证其实现 100%的可靠性。

不过在实际开发中使用 Redis 实现分布式锁还是比较常见，而且大部分场情况下不会遇到”极端复杂的场景“，更重要的是 Redis 性能很高，在高并发场景中比较合适。

对于 zk 分布式锁而言:

- zookeeper 天生设计定位就是分布式协调，强一致性。锁的模型健壮、简单易用、适合做分布式锁。
- 如果获取不到锁，只需要添加一个监听器就可以了，不用一直轮询，性能消耗较小。

> 如何选择？

Redis性能高于Zookeeper，Redis是AP模型，对可用性追求较高的可以选用Redis。

Zookeeper是CP模型，本身设计是强一致性，如果服务需要强一致性，Zookeeper好于Redis



## 对 ES 的理解  

Elasticsearch ，简称 ES 。它是建立在全文搜索引擎库 Apache Lucene 基础之上的
一个开源的搜索引擎，也可以作为 NoSQL 数据库，存储任意格式的文档和数据。也可
以做大数据的分析，是一个跨界开源产品。
它最主要的应用场景是 ELK 的日志分析系统。
另外它还有以下特点：

1. 第一、采用 Master-slave 架构，实现数据的分片和备份
2. 第二、使用 Java 编写，并对 Lucene 进行封装，隐藏了 Lucene 的复杂性
3. 第三、能胜任上百个服务节点的扩展，并支持 PB 级别的结构化或者非结构化数据
4. 第四、ES 提供的 Restful API，不仅简化了 ES 的操作，还支持任何语言的客户端提供 API 接口，另外 Restful API 的风格还实现了 CURD 操作、创建索引，删除索引等功能。  

在 ES 的使用上我也有一些经验心得，比如：

1. es 里面复杂的关联查询尽量别用，一旦用了性能都不太好。最好是先在 Java 系统里就完成关联，将关联好的数据直接写入 ES 中
2. 避免一些太复杂的操作，比如 join/nested/parent-child 搜索，不然容易出现性能问题。
3. 避免深分页查询，ES 集群的分页查询支持 from 和 size 参数，查询的时候，每个分片必须构造一个长度为 from+size 的优先队列，然后回传到网关节点，网关节点再对这些优先队列进行排序找到正确的 size 文档。当 from 足够大的时候，就算不发生 OOM，也会影响到 CPU 和带宽等，从而影响到整个集群的性能。
   

## 关于索引的底层实现,为什么选择 B+Tree 而不是红黑树？

1. 对于一个数据库来说 存储的数据量会比较多，导致索引也很大 因此需要将索引存储在磁盘，但是磁盘的 IO 操作又非常耗，所以提高索引效率的关键在于减少磁盘 IO 的次数。
   举个例子 对于 31 个节点的树来说 ，一个 5 阶 B+Tree 的高度是 3 一个红黑树的最小高度是 5，树的高度基本决定了磁盘的 IO 次数 ，所以使用 B+Tree 性能要高很多

2. B+Tree 有个特点是相邻的数据在物理上也是相邻的，因为 B+Tree 的 node 的大小设为一个页，而一个节点上存有多个相邻的关键字和分支信息，每个节点只需要一次 IO就能完全载入，相当于一次 IO 载入了多个相邻的关键字和分支，而红黑树不具有这个特性，红黑树中大小相邻的数据，在物理结构上可能距离相差很大。

   由于程序的局部性原理，如果我们在索引中采用了预加载的技术，每次磁盘访问的时候除了将访问到的页加载到磁盘，我们还可以基于局部性原理加载，几页相邻的数据到内存中，而这个加载是不需要消耗多余磁盘 IO 时间的。

   因此 基于局部性原理，以及 B+Tree 存储结构物理上的特性，所以 B+Tree 的索引性能比红黑树要好很多  



## Netty

> 简单介绍Netty

1. Netty 是一个 基于 NIO 模型的高性能网络通信框架，其实可以认为它是对 NIO 网络模。型的封装，提供了简单易用的 API，我们可以利用这些封装好的API 快速开发自己的网络程序。
2. Netty 在 NIO 的基础上做了很多优化，比如零拷贝机制、高性能无锁队列、内存池等，因此性能会比 NIO 更高。
3. Netty 可以支持多种通信协议，如 Http、WebSocket 等，并且针对数据通信的拆包黏包问题，Netty 内置了拆包策略

> 为什么要用 Netty   
>

Nety 相比于直接使用 JDK 自带的 NIO 相关的 API 来说更加易用。同时，它还具有以下特点：

1. 统一的 API，支持多种传输类型，如阻塞、非阻塞，以及 epoll、poll 等模型。
2. 我们可以使用非常少的代码来实现，多线程 Reactor 模型以及主从多线程 Reactor模型
3. 自带编解码器解决 TCP 粘包/拆包问题。
4. 自带各种协议栈。
5. 比直接使用 Java 库中的 NIO API 有更高的吞吐量、更低的延迟、更低的资源消耗和更少的内存复制  
6. 安全性不错，有完整的 SSL/TLS 以及 StartTLS 支持。
7. 社区活跃成熟稳定，经历了大型项目的使用和考验，而且很多开源项目都使用到了 Netty， 比如我们经常接触的 Dubbo、RocketMQ 等等。  

> Netty 可以做什么事情  
>

我们之所以要用 Netty，核心点还是在于解决服务器如何承载更多的用户同时访问的问题。

传统的 BIO 模型，由于阻塞的特性，使得在高并发场景中，很难获得更高的吞吐量。

而后来基于 NIO 的多路复用模型虽然在阻塞方面进行了优化，但是它的 API 使用比较复杂，对于初学者来说使用不是很友好。而 Netty 是基于 NIO 的封装，提供了成熟且简单易用的 API，降低了使用成本和学习成本。

本质上来说，Netty 和 NIO 所扮演的角色是相同的，都是为了提升服务端的吞吐量，让用户获得更好的产品体验。
另外，Netty 这个中间件经过很多年的验证，在目前主流的中间件如 Zookeeper、Dubbo、RocketMQ 中都有应用。  

> Netty 核心组件了解吗？分别有什么作用？  
>

Netty 由三层结构构成：网络通信层、事件调度器与服务编排层

**在网络通信层有三个核心组件**：Bootstrap、ServerBootStrap、Channel

- Bootstrap 负责客户端启动并用来链接远程 netty server
- ServerBootStrap 负责服务端监听，用来监听指定端口，
- Channel 是负责网络通信的载体

**事件调度器有两个核心组件**：EventLoopGroup 与 EventLoop

- EventLoopGroup 本质上是一个线程池，主要负责接收 I/O 请求，并分配线程执行处理请求。

- EventLoop。相当于线程池中的线程

  **在服务编排层有三个核心组件** ChannelPipeline、ChannelHandler、ChannelHandlerContext

- ChannelPipeline 负责将多个 Channelhandler 链接在一起  

- ChannelHandler 针对 IO 数据的处理器，数据接收后，通过指定的 Handler 进行处理。

- ChannelHandlerContext 用来保存 ChannelHandler 的上下文信息  

> Netty 有几种线程模型  以及对于这三种线程 Reactor 模型的理解  
>

Netty 提供了三种 Reactor 模型的支持

- 单线程单 Reactor 模型
- 多线程单 Reactor 模型
- 多线程多 Reactor 模型  

Reactor 模型有三个重要的组件：

1. Reactor ：将 I/O 事件发派给对应的 Handler
2. Acceptor ：处理客户端连接请求
3. Handlers ：执行非阻塞读/写

这是最基本的单 Reactor 单线程模型我们来看这张图：  

<img src="%E9%9D%A2%E7%BB%8F%E6%9D%82%E9%A1%B9.assets/image-20230824122633307.png" alt="image-20230824122633307" style="zoom:67%;" />

其中 Reactor 线程，负责多路分离套接字，有新连接到来触发 connect 事件之后，交由 Acceptor 进行处理，有 IO 读写事件之后交给 hanlder 处理。  

Acceptor 主要任务就是构建 handler ，在获取到和 client 相关的 SocketChannel 之后 ，绑定到相应的 hanlder 上，对应的 SocketChannel 有读写事件之后，基于 racotor分发,hanlder 就可以处理了（所有的 IO 事件都绑定到 selector 上，有 Reactor 分发）

> 多线程单 Reactor 模型

单线程 Reactor 这种实现方式有存在着缺点，从实例代码中可以看出，handler 的执行是串行的，如果其中一个 handler 处理线程阻塞将导致其他的业务处理阻塞。由于handler 和 reactor 在同一个线程中的执行，这也将导致无法接收新的请求。
为了解决这种问题，有人提出使用多线程的方式来处理业务，也就是在业务处理的地方加入线程池异步处理，将 reactor 和 handler 在不同的线程来执行，这就是多线程单Reactor 模型  

<img src="%E9%9D%A2%E7%BB%8F%E6%9D%82%E9%A1%B9.assets/image-20230824122810407.png" alt="image-20230824122810407" style="zoom: 50%;" />

在多线程单 Reactor 模型中，所有的 I/O 操作是由一个 Reactor 来完成，而 Reactor运行在单个线程中，它需要处理包括 Accept()/read()/write/connect 操作，对于小容量的场景，影响不大。但是对于高负载、大并发或大数据量的应用场景时，容易成为瓶颈，主要原因如下：

- 一个 NIO 线程同时处理成百上千的链路，性能上无法支撑，即便 NIO 线程的 CPU负荷达到 100%，也无法满足海量消息的读取和发送；
- 当 NIO 线程负载过重之后，处理速度将变慢，这会导致大量客户端连接超时，超时之后往往会进行重发，这更加重了 NIO 线程的负载，最终会导致大量消息积压和处理超时，成为系统的性能瓶颈；  

所以，我们还可以更进一步优化，引入多 Reactor 多线程模式  

<img src="%E9%9D%A2%E7%BB%8F%E6%9D%82%E9%A1%B9.assets/image-20230824125246233.png" alt="image-20230824125246233" style="zoom:50%;" />

Main Reactor 负责接收客户端的连接请求，然后把接收到的请求传递给SubReactor（其中 subReactor 可以有多个），具体的业务 IO 处理由 SubReactor完成。

- Acceptor，请求接收者，在实践时其职责类似服务器，并不真正负责连接请求的建立，而只将其请求委托 Main Reactor 线程池来实现，起到一个转发的作用。
- Main Reactor，主 Reactor 线程组，主要负责连接事件，并将 IO 读写请求转发到 SubReactor 线程池。
- Sub Reactor，Main Reactor 通常监听客户端连接后会将通道的读写转发到 SubReactor 线程池中一个线程(负载均衡)，负责数据的读写。在 NIO 中 通常注册通道的读(OP_READ)、写事件(OP_WRITE)。  



## 负载均衡

> 负载均衡的诞生背景

在互联网发展早期，由于用户量较少、业务需求也比较简单。对于软件应用，我们只需要一台高配的服务器即可完成业务的支撑，这样的软件架构称为单体架构（展示单
体架构的图片）  

<img src="%E9%9D%A2%E7%BB%8F%E6%9D%82%E9%A1%B9.assets/image-20230824154444204.png" alt="image-20230824154444204" style="zoom:67%;" />

随着用户量的增加，服务器的请流量也随之增加，在这个过程中单体架构会产生两个问题。

1. 软件的性能逐步下降，访问延迟越来越高

2. 容易出现单点故障
   为了解决这个问题，我们引入了集群化部署的架构，也就是把一个软件应用同时部署在多个服务器上  

<img src="%E9%9D%A2%E7%BB%8F%E6%9D%82%E9%A1%B9.assets/image-20230824154516666.png" alt="image-20230824154516666" style="zoom:67%;" />

架构的变化带来了两个问题：

1. 客户端请求如何均匀的分发到多台目标服务器上？  
2. 如何检测目标服务器的健康状态，使得客户端请求不向已经宕机的服务器发送请
   求。

为了解决这两个问题，引入了负载均衡的设计，简单来说，负载均衡机制的核心目的是让客户端的请求合理均匀的分发到多台目标服务器，由于请求被多个节点分发，使得服务端的性能得到有效的提升。  

### 如何实现负载均衡？

常见的实现方案有三种

1. 基于 DNS 实现负载均衡
2. 基于硬件实现负载均衡
3. 基于软件实现负载均衡

---

### 基于 DNS 实现负载均衡的方式

它的实现方式比较简单，只需要在 DNS服务器上针对某个域名做多个 IP 映射即可  

它的工作原理是：当用户通过域名访问某个网站时，会先通过 DNS 服务器进行域名解
析得到一个 IP 地址，DNS 服务器可以随机分配一个 IP 地址进行访问，这样就可以实现
目标服务集群的请求分发。
除此之外，DNS 还可以根据不同的地域分配就近机房的 IP，比如长沙的小伙伴，可能
会得到在湖南范围内最近的一个机房的 IP，在这个模式下可以实现「就近原则」实现请
求处理，缩短了通信距离从而提升网站访问效率。
DNS 实现负载均衡的优点是： 配置简单，实现成本低，无需额外的开发和维护。

不过**缺点**也很明显：  

- 由于 DNS 多级缓存的特性，当我们修改 DNS 配置之后，会因为缓存导致 IP 变更不及时，从而影响负载均衡的效果。
- 服务器故障切换延迟大，服务器升级不方便。我们知道 DNS 与用户之间是层层的缓存，即便是在故障发生时及时通过 DNS 修改或摘除故障服务器，但中间经过运营商的 DNS 缓存，且缓存很有可能不遵循 TTL 规则，导致 DNS 生效时间变得非常缓慢，有时候一天后还会有些许的请求流量。
- 流量调度不均衡，粒度太粗。DNS 调度的均衡性，受地区运营商 LocalDNS 返回 IP 列表的策略有关系，有的运营商并不会轮询返回多个不同的 IP 地址。另外，某个运营商 LocalDNS 背后服务了多少用户，这也会构成流量调度不均的重要因素。
- 流量分配策略太简单，支持的算法太少。DNS 一般只支持 rr 的轮询方式，流量分配策略比较简单，不支持权重、Hash 等调度算法。
- DNS 支持的 IP 列表有限制。我们知道 DNS 使用 UDP 报文进行信息传递，每个 UDP 报文大小受链路的 MTU 限制，所以报文中存储的 IP 地址数量也是非常有限的，阿里 DNS 系统针对同一个域名支持配置 10 个不同的 IP 地址。

实际上生产环境中**很少**使用这种方式来实现负载均衡，毕竟缺点很明显。

---

### 基于硬件实现负载均衡

硬件负载均衡是通过专门的硬件设备来实现负载均衡功能，是专用的负载均衡设备。目前业界典型的硬件负载均衡设备有两款：F5 和 A10。

这类设备性能强劲、功能强大，但价格非常昂贵，一般只有土豪公司才会使用此类设备，中小公司一般负担不起，业务量没那么大，用这些设备也是挺浪费的。

硬件负载均衡的优点：

- 功能强大：全面支持各层级的负载均衡，支持全面的负载均衡算法。
- 性能强大：性能远超常见的软件负载均衡器。
- 稳定性高：商用硬件负载均衡，经过了良好的严格测试，经过大规模使用，稳定性高。
- 安全防护：还具备防火墙、防 DDoS 攻击等安全功能，以及支持 SNAT 功能。

硬件负载均衡的缺点也很明显：

- 价格贵；
- 扩展性差，无法进行扩展和定制；
- 调试和维护比较麻烦，需要专业人员；

---

### 软件负载均衡

可以在普通的服务器上运行负载均衡软件，实现负载均衡功能。目前常见的有 Nginx、HAproxy、LVS。其中的区别：

- Nginx：七层负载均衡，支持 HTTP、E-mail 协议，同时也支持 4 层负载均衡；
- HAproxy：支持七层规则的，性能也很不错。OpenStack 默认使用的负载均衡软件就是 HAproxy；
- LVS：运行在内核态，性能是软件负载均衡中最高的，严格来说工作在三层，所以更通用一些，适用各种应用服务。

软件负载均衡的优点：

- 易操作：无论是部署还是维护都相对比较简单；
- 便宜：只需要服务器的成本，软件是免费的；
- 灵活：4 层和 7 层负载均衡可以根据业务特点进行选择，方便进行扩展和定制功能。
- 开源，不同企业对于负载均衡的要求有差异，所以可以基于开源软件上做二次开发。  

nginx原理：https://blog.csdn.net/qq_45758854/article/details/120490140



软件负载均衡主要包括：Nginx、HAproxy 和 LVS，三款软件都比较常用。四层负载均衡基本上都会使用 LVS，据了解 BAT 等大厂都是 LVS 重度使用者，就是因为 LVS 非常出色的性能，能为公司节省巨大的成本。

LVS，全称 Linux Virtual Server 是由国人章文嵩博士发起的一个开源的项目，在社区具有很大的热度，是一个基于四层、具有强大性能的反向代理服务器。

它现在是标准内核的一部分，它具备可靠性、高性能、可扩展性和可操作性的特点，从而以低廉的成本实现最优的性能。

原理参考：https://zhuanlan.zhihu.com/p/442241881

负载均衡的作用范围
负载均衡是作用在网络通信上，来实现请求的分发。
而在网络架构中，基于 OSI 模型，又分为 7 层网络模型  

<img src="%E9%9D%A2%E7%BB%8F%E6%9D%82%E9%A1%B9.assets/image-20230824171146238.png" alt="image-20230824171146238" style="zoom: 50%;" />

也就是意味着我们可以在网络的某些分层上做请求分发处理，因此根据这样一个特性，
对于负载均衡的作用范围又可以分为：

1. 二层负载

   基于 Mac 地址来实现请求分发，一般采用虚拟 Mac 的方式实现，服务器收到请求后，通过动态分配后端服务的实际 Mac 地址进行响应从而实现负载均衡

2. 三层负载

   基于 IP 层负载，一般通过虚拟 IP 的方式实现，外部请求访问虚拟 IP，服务器收到请求后根据后端实际 IP 地址进行转发。

3. 四层负载

   通过请求报文中的目标地址和端口进行负载，Nginx、F5、LVS 等都可以实现四层负载。

4. 七层负载

   七层负载是基于应用层负载，也就是服务器端可以根据 http 协议中请求的报文信息来决定把请求分发到哪个目标服务器上，比如 Cookie、消息体、RequestHeader 等。  

### 负载均衡的常用算法

所谓负载均衡算法，就是决定当前客户端请求匹配到目标服务器集群中的具体哪个节点。
常见的负载均衡算法有：

1. 轮训，也就是多个服务器按照顺序轮训返回，这样每个服务器都能获得相同的请求次数  
2. 随机，根据随机算法获得一个目标服务地址（就像古时候皇帝翻牌子），由于该算法具备随机性，因此每个服务器获得的请求数量不一定均等。
3. 一致性 hash，也就是对于具有相同 hash 码的请求，永远发送到同一个节点上。
4. 最小连接数，根据目标服务器的请求数量来决定请求分发的权重，也就是目标服务集群中，请求更少的节点将会获得更多的请求。这是负载均衡中比较好的策略，真正能够实现目标服务器的请求均衡。  



## Spring 中事务的传播行为有哪些？  

它解决的核心问题是，多个声明了事务的方法相互调用的时候存在事务嵌套问题，那么这个事务的行为应该如何进行传递？
（如图）比如说，methodA()调用 methodB()，两个方法都显示的开启了事务。
那么 methodB()是开启一个新事务，还是继续在 methodA()这个事务中执行？就取决于事务的传播行为。  

<img src="%E9%9D%A2%E7%BB%8F%E6%9D%82%E9%A1%B9.assets/image-20230825123154447.png" alt="image-20230825123154447" style="zoom:67%;" />

所以，Spring 为了解决这个问题，定义了 7 种事务传播行为。

1. REQUIRED：默认的 Spring 事物传播级别，如果当前存在事务，则加入这个事务，如果不存在事务，就新建一个事务。
2. REQUIRE_NEW：不管是否存在事务，都会新开一个事务，新老事务相互独立。外部事务抛出异常回滚不会影响内部事务的正常提交。
3. NESTED：如果当前存在事务，则嵌套在当前事务中执行。如果当前没有事务，则新建一个事务，类似于 REQUIRE_NEW。  
4. SUPPORTS：表示支持当前事务，如果当前不存在事务，以非事务的方式执行。
5. NOT_SUPPORTED：表示以非事务的方式来运行，如果当前存在事务，则把当前事务挂起。
6. MANDATORY：强制事务执行，若当前不存在事务，则抛出异常.
7. NEVER：以非事务的方式执行，如果当前存在事务，则抛出异常  

## Mybatis 里面的缓存机制  

Mybatis 里面设计的二级缓存是用来提升数据的检索效率，避免每次数据的访问都需要去查询数据库。
一级缓存，是 SqlSession 级别的缓存，也叫本地缓存，因为每个用户在执行查询的时候都需要使用 SqlSession 来执行，
为了避免每次都去查数据库，Mybatis 把查询出来的数据保存到 SqlSession 的本地缓存中，后续的 SQL 如果命中缓存，就可以直接从本地缓存读取了。
如果想要实现跨 SqlSession 级别的缓存？那么一级缓存就无法实现了，因此在 Mybatis 里面引入了二级缓存，就是当多个用户  

在查询数据的时候，只有有任何一个 SqlSession 拿到了数据就会放入到二级缓存里面，
其他的 SqlSession 就可以从二级缓存加载数据  

<img src="%E9%9D%A2%E7%BB%8F%E6%9D%82%E9%A1%B9.assets/image-20230825123756592.png" alt="image-20230825123756592" style="zoom:67%;" />

每个一级缓存的具体实现原理是：

在 SqlSession 里面持有一个 Executor，每个 Executor 中有一个 LocalCache 对象。当用户发起查询的时候，Mybatis 会根据执行语句在 Local Cache 里面查询，如果没命中，再去查询数据库并写入到 LocalCache，否则直接返回。所以，以及缓存的生命周期是 SqlSessiion，而且在多个 Sqlsession 或者分布式环境下，可能会导致数据库写操作出现脏数据  

<img src="%E9%9D%A2%E7%BB%8F%E6%9D%82%E9%A1%B9.assets/image-20230825123901701.png" alt="image-20230825123901701" style="zoom:67%;" />

二级缓存的具体实现原理是：

使用 CachingExecutor 装饰了 Executor，所以在进入一级缓存的查询流程之前，会先通过 CachingExecutor 进行二级缓存的查询  

开启二级缓存以后，会被多个 SqlSession 共享，所以它是一个全局缓存。因此它的查询流程是先查二级缓存，再查一级缓存，最后再查数据库。

另外，MyBatis 的二级缓存相对于一级缓存来说，实现了 SqlSession 之间缓存数据的共享，同时缓存粒度也能够到 namespace 级别，并且还可以通过 Cache 接口实现类不同的组合，对 Cache 的可控性也更强  

<img src="%E9%9D%A2%E7%BB%8F%E6%9D%82%E9%A1%B9.assets/image-20230825123938062.png" alt="image-20230825123938062" style="zoom:67%;" />

二级缓存的设计思想非常常见，比如 Nacos、Eureka 都用到了.

## Java SPI 是什么？有什么用？  

Java SPI，全称是 Service Provider Interface。它是一种基于接口的动态扩展机制，相当于 Java 里面提供了一套接口。然后第三方可以实现这个接口来完成功能的扩展和实现。

举个简单的例子。
在 Java 的 SDK 里面，提供了一个数据库驱动的接口 java.sql.Driver。它的作用是提供数据库的访问能力。

不过，在 Java 里面并没有提供实现，因为不同的数据库厂商，会有不同的语法和实现。

所以只能由第三方数据库厂商来实现，比如Oracle是oracle.jdbc.OracleDriver，mysql是 com.mysql.jdbc.Driver.
然后在应用开发的时候，根据集成的驱动实现连接到对应数据库  

![image-20230825171011804](%E9%9D%A2%E7%BB%8F%E6%9D%82%E9%A1%B9.assets/image-20230825171011804.png)

Java 中 SPI 机制主要思想是将装配的控制权移到程序之外实现标准和实现的解耦，以及提供动态可插拔的能力，在模块化的设立中，这种思想非常重要。

实现 Java SPI，需要满足几个基本的格式（如图）：

- 需要先定义一个接口，作为扩展的标准
- 在 classpath 目录下创建 META-INF/service 文件目录
- 在这个目录下，以接口的全限定名命名的配置文件， 文件内容是这个接口的实现类
- 在应用程序里面，使用 ServiceLoad，就可以根据接口名称找到 classpath 所有的扩展时间, 然后根据上下文场景选择实现类完成功能的调用。  

![image-20230825171032930](%E9%9D%A2%E7%BB%8F%E6%9D%82%E9%A1%B9.assets/image-20230825171032930.png)

Java SPI 有一定的不足之处，比如，不能根据需求去加载扩展实现，每次都会加载扩展接口的所有实现类并进行实例化，
实例化会造成性能开销，并且加载一些不需要用到的实现类，会导致内存资源的浪费，

## 对 SPI 机制的理解以及 Dubbo 中有哪些SPI 机制的实现  

SPI 全称为 Service Provider Interface，是 Java 中一种服务发现机制。在 SPI 机制中，服务提供者为某个接口实现具体的类，而在运行时，通过 SPI 机制，查找到对应的实现类，并将其加载进行使用。
比较典型的一个例子就是 java.jdbc.Driver 这个数据库驱动接口，在 Java 中只提供了接口的定义，
具体的实现类由各个数据库厂商提供的驱动包来完成，程序在运行的时候会根据当前导入的驱动包来完成对应数据库的连接  

在 Dubbo 中，根据 Java SPI 的思想，衍生了不同的 SPI 实现。

- 指定名称的扩展点实现，也就是根据指定名称获取并加载对应的扩展点实现类
- @Adaptive 注解定义自适应扩展点，它会根据上下文参数动态适配一个具体的实现类
- @Activate 注解定义的激活扩展点，它会根据上下文的相关参数配置，来决定哪些扩展点会被动态激活，主要体现在 Filter 中。

SPI 思想可以为程序提供比较强大的的可扩展性能力，在企业级开发中，可以尝试去借鉴和使用  

## AbstractQueuedSynchronized 为什么采用双向链表  

第一个方面，双向链表的优势：

- 双向链表提供了双向指针，可以在任何一个节点方便向前或向后进行遍历，这种对于有反向遍历需求的场景来说非常有用。
- 双向链表可以在任意节点位置实现数据的插入和删除，并且这些操作的时间复杂度都是 O(1)，不受链表长度的影响。这对于需要频繁对链表进行增删操作的场景非常有用。

第二个方面，说一下 AQS 采用双向链表的原因

- 存储在双向链表中的线程，有可能这个线程出现异常不再需要竞争锁，所以需要把这些异常节点从链表中删除，而删除操作需要找到这个节点的前驱结点，如果不采用双向链表，就必须要从头节点开始遍历，时间复杂度就变成了 O(n)。  

<img src="%E9%9D%A2%E7%BB%8F%E6%9D%82%E9%A1%B9.assets/image-20230825131529631.png" alt="image-20230825131529631" style="zoom:67%;" />

新加入到链表中的线程，在进入到阻塞状态之前，需要判断前驱节点的状态，只有前驱节点是 Sign 状态的时候才会让当前线程阻塞，所以这里也会涉及到前驱节点的查找，采用双向链表能够更好的提升查找效率  

<img src="%E9%9D%A2%E7%BB%8F%E6%9D%82%E9%A1%B9.assets/image-20230825131553164.png" alt="image-20230825131553164" style="zoom:67%;" />

线程在加入到链表中后，会通过自旋的方式去尝试竞争锁来提升性能，在自旋竞争锁的时候为了保证锁竞争的公平性，需要先判断当前线程所在节点的前驱节点是否是头节点。这个判断也需要获取当前节点的前驱节点，同样采用双向链表能提高查
找效率。  

<img src="%E9%9D%A2%E7%BB%8F%E6%9D%82%E9%A1%B9.assets/image-20230825131611853.png" alt="image-20230825131611853" style="zoom:67%;" />

总而言之，采用单向链表不支持双向遍历，而 AQS 中存在很多需要双向遍历的场景来提升线程阻塞和唤醒的效率。  



## Mysql 深分页优化

https://zhuanlan.zhihu.com/p/617388002



## 如何破坏双亲委派模型  

第一种情况，双亲委派是在 JDK1.2 版本发布的，而类加载器和抽象类 ClassLoader 在JDK1.0 就已经存在了，用户可以通过重写 ClassLoader 里面的 loadClass()方法实现自定义类加载，JDK1.2 为了向前兼容，所以在设计的时候需要兼容 loadClass()重写的实现，导致双亲委派被破坏的情况。

同时，为了避免后续再出现这样的问题，不在提倡重写 loadClass()方法，而是使用JDK1.2 中 ClassLoader 中提供了 findClass 方法来实现符合双亲委派规则的类加载逻辑。

第二种情况，在这个类加载模型中，有可能存在顶层|类加载器加载的类，需要调用用户类加载器实现的代码的情况。
比如 java.jdbc.Driver 接口，它只是一个数据库驱动接口，这个接口是由启动类加载器加载的。但是 java.jdbc.Driver 接口的实现是由各大数据库厂商来完成的，既然是自己实现的代码，就应该由应用类加载器来加载。
于是就出现了启动类加载器加载的类要调用应用类加载器加载的实现。

为了解决这个问题，在 JVM 中引入了线程上下文类加载器，它可以把原本需要启动类加载器加载的类，由应用类加载器进行加载。

除此之外，像 Tomcat 容器，也存在破坏双亲委派的情况，来实现不同应用之间的资源隔离。  

> 总结

1. 集成 ClassLoader 抽象类，重写 loadClass 方法，在这个方法可以自定义要加载的类使用的类加载器。
2. 使用线程上下文加载器，可以通过 java.lang.Thread 类的 setContextClassLoader()方法来设置当前类使用的类加载器类型。  



## select 和 epoll 的区别  

select 和 epoll 都是 I/O 多路复用的机制，它们可以让一个进程监听多个文件描述符的 IO 事件或者连接事件，

只要其中任意一个或多个文件描述符就绪，就会触发阻塞唤醒，使得应用程序可以直接进行数据的读取或者写入  

它们的区别主要有几个方面：

1. select 是基于轮询的机制，它需要遍历整个监听集合，直到找到就绪的文件描述符。
   而 epoll 是基于事件通知的机制，它只需要遍历当前就绪的文件描述符集合，大大减少了遍历的次数和开销。
2. select 的监听集合大小有限，一般受到操作系统的限制，而 epoll 没有这个限制，可以监听大量的文件描述符。
3. 在处理大量文件描述符时，select 的性能随着监听集合的增大而逐渐下降，而epoll 的性能则能够保持稳定。
4. 在多线程环境下，select 需要将监听集合传递给每个线程，而 epoll 可以在一个线程中处理多个文件描述符，避免了线程间的切换和数据复制等开销。

从对比中不难发现，epoll 相比于 select 在性能和扩展性方面都有很大的优势，所以通常在企业级应用中使用较多的还是 epoll。

但是在一些特定的场景下，select 也有它的优势，例如在处理少量文件描述符或需要跨平台支持的情况下，select 是一个更好的选择。  































